Business AI Agent Implementation Plan                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Assignment: Lead AI Engineer - E-commerce Analytics Agent with Strands  â”‚
     â”‚ SDK                                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ âš ï¸ CRITICAL CONSTRAINTS & APPROACH                                      â”‚
     â”‚                                                                         â”‚
     â”‚ Status: Plan revised with assignment constraints and Strands SDK review â”‚
     â”‚ Last Updated: After constraint clarification and SDK documentation      â”‚
     â”‚ review                                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸ”´ CRITICAL CONSTRAINTS (Must Follow)                                   â”‚
     â”‚                                                                         â”‚
     â”‚ 1. generate_data.py is IMMUTABLE                                        â”‚
     â”‚   - Assignment-provided, cannot be modified                             â”‚
     â”‚   - Uses datetime.now() intentionally - datasets will differ across     â”‚
     â”‚ machines                                                                â”‚
     â”‚   - This is by design, not a bug                                        â”‚
     â”‚ 2. Time Logic MUST Be Dataset-Anchored                                  â”‚
     â”‚   - Define data_end = max(transaction_date) from loaded data            â”‚
     â”‚   - "This month" = month containing data_end                            â”‚
     â”‚   - "Last month" = month immediately preceding data_end                 â”‚
     â”‚   - NO hardcoded dates or system clock references                       â”‚
     â”‚ 3. Tests MUST Be Dataset-Agnostic                                       â”‚
     â”‚   - Contract-based assertions (types, relationships, invariants)        â”‚
     â”‚   - NO hardcoded revenue values or specific dates                       â”‚
     â”‚   - Validate: "revenue > 0", not "revenue == 450000"                    â”‚
     â”‚   - Validate: "categories.length == 5", not specific amounts            â”‚
     â”‚ 4. Incremental Implementation (STEP 1 ONLY)                             â”‚
     â”‚   - Project skeleton + data loading + ONE tool + tests                  â”‚
     â”‚   - STOP and wait for approval before proceeding                        â”‚
     â”‚   - NO full implementation upfront                                      â”‚
     â”‚ 5. Strands SDK Patterns (Documented)                                    â”‚
     â”‚   - Use @tool decorator with docstrings and type hints                  â”‚
     â”‚   - OpenAIModel with client_args and params                             â”‚
     â”‚   - Tools return JSON-serializable objects/dicts                        â”‚
     â”‚   - Pydantic models supported for structured returns                    â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸ‘‰ Approach: Build stable architecture skeleton, implement              â”‚
     â”‚ incrementally, validate at each step                                    â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Executive Summary                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Building a production-grade AI agent that answers business questions    â”‚
     â”‚ about e-commerce data using structured tools with pandas backend. This  â”‚
     â”‚ hybrid approach balances LLM reliability, output consistency, and       â”‚
     â”‚ analytical flexibility.                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Key Technical Decision: Use domain-specific analytical tools (5 focused â”‚
     â”‚ functions) that return Pydantic-validated structured outputs, backed by â”‚
     â”‚ pandas computations. This demonstrates production-ready architecture    â”‚
     â”‚ while maintaining practical implementation speed.                       â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Architecture Overview                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Three-Layer Architecture                                                â”‚
     â”‚                                                                         â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
     â”‚ â”‚  AI Orchestration Layer (agent.py)                  â”‚                 â”‚
     â”‚ â”‚  - OpenAI GPT-4 (temp=0.0 for deterministic)       â”‚                  â”‚
     â”‚ â”‚  - Strands Agent with tool registry                 â”‚                 â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
     â”‚                         â†“                                               â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
     â”‚ â”‚  Business Logic Layer (analytics.py)                â”‚                 â”‚
     â”‚ â”‚  - 5 analytical tools (@tool decorated)             â”‚                 â”‚
     â”‚ â”‚  - Returns Pydantic models (structured outputs)     â”‚                 â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
     â”‚                         â†“                                               â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
     â”‚ â”‚  Data Access Layer (data_loader.py)                 â”‚                 â”‚
     â”‚ â”‚  - DataManager class                                â”‚                 â”‚
     â”‚ â”‚  - Pandas DataFrames in memory                      â”‚                 â”‚
     â”‚ â”‚  - CSV loading & caching                            â”‚                 â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
     â”‚                                                                         â”‚
     â”‚ Why This Architecture?                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ Separation of Concerns: Each layer has single responsibility            â”‚
     â”‚ - AI Layer: Tool selection and response generation                      â”‚
     â”‚ - Logic Layer: Business calculations and validation                     â”‚
     â”‚ - Data Layer: Raw data access                                           â”‚
     â”‚                                                                         â”‚
     â”‚ Testability: Each layer can be tested independently with mocks          â”‚
     â”‚                                                                         â”‚
     â”‚ Maintainability: Clear boundaries make debugging and extension          â”‚
     â”‚ straightforward                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Interview-Ready: Shows systems thinking and production mindset          â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Core Architectural Decision: Tool Design                                â”‚
     â”‚                                                                         â”‚
     â”‚ Chosen Approach: Structured Analytical Tools                            â”‚
     â”‚                                                                         â”‚
     â”‚ Pattern: One tool per question type, returning Pydantic-validated modelsâ”‚
     â”‚                                                                         â”‚
     â”‚ Why This Beats Alternatives:                                            â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”                                                                   â”‚
     â”‚ â”‚  Approach   â”‚         Pros          â”‚       Cons       â”‚     Verdict  â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”¤                                                                   â”‚
     â”‚ â”‚ Structured  â”‚ âœ… LLM-friendlyâœ…     â”‚                  â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚ Tools       â”‚ Testableâœ… Consistent â”‚ âš ï¸ More upfront  â”‚ BEST for     â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚ (CHOSEN)    â”‚  outputsâœ…            â”‚ design           â”‚ assignment   â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚             â”‚ Production-ready      â”‚                  â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”¤                                                                   â”‚
     â”‚ â”‚ Raw SQL +   â”‚                       â”‚ âŒ Unpredictable â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚ LLM queries â”‚ âœ… Flexible           â”‚  outputsâŒ Hard  â”‚ âŒ Too risky â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚             â”‚                       â”‚ to test          â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”¤                                                                   â”‚
     â”‚ â”‚             â”‚                       â”‚ âŒ Security      â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚ LLM code    â”‚ âœ… Maximum            â”‚ concernsâŒ       â”‚ âŒ Not       â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚ generation  â”‚ flexibility           â”‚ UntestableâŒ     â”‚              â”‚
     â”‚ production-grade â”‚                                                      â”‚
     â”‚ â”‚             â”‚                       â”‚ Inconsistent     â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”¤                                                                   â”‚
     â”‚ â”‚ Pre-built   â”‚                       â”‚ âŒ InflexibleâŒ  â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚ functions   â”‚ âœ… Simple             â”‚ Can't handle     â”‚ âŒ Too rigid â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â”‚ only        â”‚                       â”‚ variations       â”‚              â”‚
     â”‚     â”‚                                                                   â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”˜                                                                   â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Technical Rationale:                                                    â”‚
     â”‚ - For LLM Success: Simpler tool signatures = higher selection accuracy  â”‚
     â”‚ - For Output Quality: Pydantic validation guarantees structure          â”‚
     â”‚ - For Testing: Known inputs â†’ known outputs = comprehensive test        â”‚
     â”‚ coverage                                                                â”‚
     â”‚ - For Pandas Preference: Analytical logic uses pandas behind the scenes â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Project Structure                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ business-ai-agent/                                                      â”‚
     â”‚ â”œâ”€â”€ .env.example                  # API key template                    â”‚
     â”‚ â”œâ”€â”€ .env                          # Your actual keys (gitignored)       â”‚
     â”‚ â”œâ”€â”€ README.md                     # Setup instructions & design doc     â”‚
     â”‚ â”œâ”€â”€ requirements.txt              # Dependencies list                   â”‚
     â”‚ â”œâ”€â”€ generate_data.py              # Data generation (ROOT LEVEL - per   â”‚
     â”‚ assignment)                                                             â”‚
     â”‚ â”‚                                                                       â”‚
     â”‚ â”œâ”€â”€ data/                         # Generated CSV files                 â”‚
     â”‚ â”‚   â”œâ”€â”€ transactions.csv          # 5K e-commerce transactions          â”‚
     â”‚ â”‚   â””â”€â”€ customers.csv             # 200 customers                       â”‚
     â”‚ â”‚                                                                       â”‚
     â”‚ â”œâ”€â”€ src/                                                                â”‚
     â”‚ â”‚   â”œâ”€â”€ __init__.py                                                     â”‚
     â”‚ â”‚   â”œâ”€â”€ config.py                 # Environment variables & constants   â”‚
     â”‚ â”‚   â”œâ”€â”€ data_loader.py           # DataManager class (CSV â†’ pandas)     â”‚
     â”‚ â”‚   â”œâ”€â”€ models.py                # Pydantic output schemas (7 models +  â”‚
     â”‚ AgentResponse)                                                          â”‚
     â”‚ â”‚   â”œâ”€â”€ analytics.py             # 5+ analytical tools (core business   â”‚
     â”‚ logic)                                                                  â”‚
     â”‚ â”‚   â”œâ”€â”€ agent.py                 # Strands Agent + OpenAI configuration â”‚
     â”‚ â”‚   â””â”€â”€ (utils.py)               # Optional: only if needed             â”‚
     â”‚ â”‚                                                                       â”‚
     â”‚ â”œâ”€â”€ tests/                                                              â”‚
     â”‚ â”‚   â”œâ”€â”€ __init__.py                                                     â”‚
     â”‚ â”‚   â”œâ”€â”€ pytest.ini               # Configure pytest (skip API tests by  â”‚
     â”‚ default)                                                                â”‚
     â”‚ â”‚   â”œâ”€â”€ test_analytics.py        # Unit tests (NO API KEY REQUIRED)     â”‚
     â”‚ â”‚   â”œâ”€â”€ test_agent_integration.py # Integration tests                   â”‚
     â”‚ (@requires_api_key)                                                     â”‚
     â”‚ â”‚   â””â”€â”€ expected_outputs/        # Golden files for validation          â”‚
     â”‚ â”‚                                                                       â”‚
     â”‚ â”œâ”€â”€ demo.py                       # Showcase script (3 questions)       â”‚
     â”‚ â””â”€â”€ (run_agent.py)                # Optional: CLI interface             â”‚
     â”‚                                                                         â”‚
     â”‚ Key Changes from Critical Review:                                       â”‚
     â”‚ - âœ… generate_data.py at root level (aligns with assignment)            â”‚
     â”‚ - âœ… Removed src/data_generator.py (was redundant)                      â”‚
     â”‚ - âœ… Updated data scale to 5K/200 (matches existing script)             â”‚
     â”‚ - âœ… Added AgentResponse to models count                                â”‚
     â”‚ - âœ… Split tests into tool vs agent integration                         â”‚
     â”‚ - âœ… Added pytest.ini and expected_outputs/                             â”‚
     â”‚ - âš ï¸ utils.py and run_agent.py marked optional (skip if not needed)     â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ The 5+ Analytical Tools                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Each tool maps to one assignment question and returns a structured      â”‚
     â”‚ Pydantic model.                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Note: After critical review, tools have been enhanced with optional     â”‚
     â”‚ parameters for flexibility.                                             â”‚
     â”‚                                                                         â”‚
     â”‚ Tool 1: calculate_revenue_by_category()                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Question: "What is our total revenue by category?"                      â”‚
     â”‚                                                                         â”‚
     â”‚ Signature (Enhanced):                                                   â”‚
     â”‚ def calculate_revenue_by_category(                                      â”‚
     â”‚     start_date: Optional[str] = None,                                   â”‚
     â”‚     end_date: Optional[str] = None,                                     â”‚
     â”‚     categories: Optional[List[str]] = None  # Filter specific categoriesâ”‚
     â”‚ ) -> RevenueByCategory                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ Returns: RevenueByCategory model                                        â”‚
     â”‚ - List of categories with revenue, transaction count, AOV               â”‚
     â”‚ - Total revenue across all categories                                   â”‚
     â”‚ - Top-performing category                                               â”‚
     â”‚                                                                         â”‚
     â”‚ Implementation: Filter out returns, optionally filter by date/category, â”‚
     â”‚ group by category, sum amounts                                          â”‚
     â”‚                                                                         â”‚
     â”‚ Question Variations Supported:                                          â”‚
     â”‚ - "What is our total revenue by category?" (all categories)             â”‚
     â”‚ - "What's revenue for electronics?" (categories=["electronics"])        â”‚
     â”‚ - "Revenue by category in Q4 2024?" (start/end dates)                   â”‚
     â”‚                                                                         â”‚
     â”‚ Tool 2: calculate_customer_ltv()                                        â”‚
     â”‚                                                                         â”‚
     â”‚ Question: "Which customers have the highest lifetime value?"            â”‚
     â”‚                                                                         â”‚
     â”‚ Signature (Enhanced):                                                   â”‚
     â”‚ def calculate_customer_ltv(                                             â”‚
     â”‚     top_n: int = 10,                                                    â”‚
     â”‚     region: Optional[str] = None,      # Filter by region               â”‚
     â”‚     segment: Optional[str] = None,     # Filter by segment              â”‚
     â”‚     min_transactions: int = 1                                           â”‚
     â”‚ ) -> CustomerLifetimeValue                                              â”‚
     â”‚                                                                         â”‚
     â”‚ Returns: CustomerLifetimeValue model                                    â”‚
     â”‚ - Top N customers ranked by total spending                              â”‚
     â”‚ - Each customer: total_spent, transaction_count, AOV, segment, region   â”‚
     â”‚ - Average LTV across all customers                                      â”‚
     â”‚                                                                         â”‚
     â”‚ Implementation: Join transactions + customers, optionally filter by     â”‚
     â”‚ region/segment, group by customer_id, rank by total                     â”‚
     â”‚                                                                         â”‚
     â”‚ Question Variations Supported:                                          â”‚
     â”‚ - "Top 10 customers by LTV?" (default)                                  â”‚
     â”‚ - "Top 5 customers in the North region?" (top_n=5, region="north")      â”‚
     â”‚ - "Highest value VIP customers?" (segment="vip")                        â”‚
     â”‚                                                                         â”‚
     â”‚ Tool 3: calculate_return_rate()                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Question: "What's the return rate by product category?"                 â”‚
     â”‚                                                                         â”‚
     â”‚ Signature:                                                              â”‚
     â”‚ def calculate_return_rate() -> ReturnRateByCategory                     â”‚
     â”‚                                                                         â”‚
     â”‚ Returns: ReturnRateByCategory model                                     â”‚
     â”‚ - Per category: total transactions, returned count, return rate %       â”‚
     â”‚ - Revenue impact of returns                                             â”‚
     â”‚ - Category with highest return rate                                     â”‚
     â”‚                                                                         â”‚
     â”‚ Implementation: Group by category, count where is_returned=True,        â”‚
     â”‚ calculate percentages                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Tool 4: compare_regions()                                               â”‚
     â”‚                                                                         â”‚
     â”‚ Question: "Compare performance across regions"                          â”‚
     â”‚                                                                         â”‚
     â”‚ Signature:                                                              â”‚
     â”‚ def compare_regions() -> RegionPerformance                              â”‚
     â”‚                                                                         â”‚
     â”‚ Returns: RegionPerformance model                                        â”‚
     â”‚ - Per region: revenue, customer count, transaction count, AOV, return   â”‚
     â”‚ rate                                                                    â”‚
     â”‚ - Top-performing region                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Implementation: Join on customer_id, group by region, aggregate metrics â”‚
     â”‚                                                                         â”‚
     â”‚ Tool 5: compare_time_periods()                                          â”‚
     â”‚                                                                         â”‚
     â”‚ Question: "How is this month performing compared to last month?"        â”‚
     â”‚                                                                         â”‚
     â”‚ Signature (Enhanced):                                                   â”‚
     â”‚ def compare_time_periods(                                               â”‚
     â”‚     period_label: str = "custom",  # "month_over_month", "Q4_vs_Q3",    â”‚
     â”‚ "custom"                                                                â”‚
     â”‚     reference_date: Optional[str] = None,  # Defaults to data end date  â”‚
     â”‚     current_start: Optional[str] = None,                                â”‚
     â”‚     current_end: Optional[str] = None,                                  â”‚
     â”‚     previous_start: Optional[str] = None,                               â”‚
     â”‚     previous_end: Optional[str] = None                                  â”‚
     â”‚ ) -> PeriodComparison                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Returns: PeriodComparison model                                         â”‚
     â”‚ - Current period metrics vs previous period metrics                     â”‚
     â”‚ - Percentage changes (revenue, transactions)                            â”‚
     â”‚ - Growth/decline interpretation                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Implementation: If period_label provided, auto-calculate dates;         â”‚
     â”‚ otherwise use provided dates. Filter by ranges, calculate metrics,      â”‚
     â”‚ compute deltas.                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Question Variations Supported:                                          â”‚
     â”‚ - "This month vs last month?" (period_label="month_over_month")         â”‚
     â”‚ - "December vs November 2024?" (custom dates)                           â”‚
     â”‚ - "Q4 vs Q3 performance?" (period_label="Q4_vs_Q3")                     â”‚
     â”‚                                                                         â”‚
     â”‚ Tool 6 (NEW): explain_capabilities()                                    â”‚
     â”‚                                                                         â”‚
     â”‚ Purpose: Handle unsupported questions gracefully                        â”‚
     â”‚                                                                         â”‚
     â”‚ Signature:                                                              â”‚
     â”‚ def explain_capabilities() -> dict                                      â”‚
     â”‚                                                                         â”‚
     â”‚ Returns: Dictionary with available analyses and example questions       â”‚
     â”‚                                                                         â”‚
     â”‚ Use Case: When agent receives a question that can't be answered with    â”‚
     â”‚ available tools                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Data Generation Strategy                                                â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… generate_data.py File Analysis Complete                              â”‚
     â”‚                                                                         â”‚
     â”‚ File Location:                                                          â”‚
     â”‚ /Users/adibaram/Documents/projects/business-ai-agent/generate_data.py   â”‚
     â”‚ (root level - assignment-provided)                                      â”‚
     â”‚                                                                         â”‚
     â”‚ Status: âš ï¸ IMMUTABLE - Cannot Be Modified                               â”‚
     â”‚                                                                         â”‚
     â”‚ What It Does:                                                           â”‚
     â”‚ - Generates 5,000 transactions and 200 customers                        â”‚
     â”‚ - Uses random.seed(42) for reproducibility âœ“                            â”‚
     â”‚ - Creates two CSV files with assignment-compliant schema âœ“              â”‚
     â”‚ - Uses triangular distribution for realistic date patterns âœ“            â”‚
     â”‚ - Outputs to current directory (customers.csv, transactions.csv)        â”‚
     â”‚                                                                         â”‚
     â”‚ Intentional Design:                                                     â”‚
     â”‚ 1. âœ… Line 29: Uses datetime.now().date() - INTENTIONAL, datasets will  â”‚
     â”‚ differ across machines                                                  â”‚
     â”‚ 2. âœ… Lines 44, 82: Writes to current directory - AS DESIGNED,          â”‚
     â”‚ assignment-provided behavior                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Schema Validation:                                                      â”‚
     â”‚ - âœ… All assignment-required fields present                             â”‚
     â”‚ - âœ… Correct data types and formats                                     â”‚
     â”‚ - âœ… Foreign key relationship (customer_id) properly implemented        â”‚
     â”‚ - âœ… Proper ID formats (CUST-0000, TXN-000000)                          â”‚
     â”‚                                                                         â”‚
     â”‚ Data Characteristics Confirmed:                                         â”‚
     â”‚ - Customer segments: 30% new, 50% regular, 20% vip âœ“                    â”‚
     â”‚ - Categories: 5 types (electronics, clothing, home, grocery, sports) âœ“  â”‚
     â”‚ - Regions: 4 types (north, south, east, west) âœ“                         â”‚
     â”‚ - Return rate: 8% uniform âœ“                                             â”‚
     â”‚ - Pricing: Base prices with 50-200% variance âœ“                          â”‚
     â”‚ - Date distribution: Triangular with mode at 60 days ago (recent bias) âœ“â”‚
     â”‚                                                                         â”‚
     â”‚ Plan Alignment: âœ… Plan correctly reflects actual implementation        â”‚
     â”‚                                                                         â”‚
     â”‚ Data Loading Strategy (Dataset-Anchored Time Logic)                     â”‚
     â”‚                                                                         â”‚
     â”‚ Since generate_data.py cannot be modified, we must adapt to its output: â”‚
     â”‚                                                                         â”‚
     â”‚ # src/data_loader.py approach                                           â”‚
     â”‚                                                                         â”‚
     â”‚ class DataManager:                                                      â”‚
     â”‚     def __init__(self, data_dir: str = "."):                            â”‚
     â”‚         """Load data and compute dataset boundaries."""                 â”‚
     â”‚         self.transactions = pd.read_csv(f"{data_dir}/transactions.csv") â”‚
     â”‚         self.customers = pd.read_csv(f"{data_dir}/customers.csv")       â”‚
     â”‚                                                                         â”‚
     â”‚         # Convert date strings to datetime                              â”‚
     â”‚         self.transactions['transaction_date'] = pd.to_datetime(         â”‚
     â”‚             self.transactions['transaction_date']                       â”‚
     â”‚         )                                                               â”‚
     â”‚         self.customers['signup_date'] = pd.to_datetime(                 â”‚
     â”‚             self.customers['signup_date']                               â”‚
     â”‚         )                                                               â”‚
     â”‚                                                                         â”‚
     â”‚         # â­ CRITICAL: Anchor time logic to the dataset itself          â”‚
     â”‚         self.data_start = self.transactions['transaction_date'].min()   â”‚
     â”‚         self.data_end = self.transactions['transaction_date'].max()     â”‚
     â”‚                                                                         â”‚
     â”‚         # Define "this month" and "last month" relative to data_end     â”‚
     â”‚         self.current_month_start = self.data_end.replace(day=1)         â”‚
     â”‚         self.current_month_end = self.data_end                          â”‚
     â”‚                                                                         â”‚
     â”‚         # Calculate previous month boundaries                           â”‚
     â”‚         last_month_end = self.current_month_start - timedelta(days=1)   â”‚
     â”‚         self.prev_month_start = last_month_end.replace(day=1)           â”‚
     â”‚         self.prev_month_end = last_month_end                            â”‚
     â”‚                                                                         â”‚
     â”‚     def get_date_context(self) -> dict:                                 â”‚
     â”‚         """Return dataset date boundaries for tools."""                 â”‚
     â”‚         return {                                                        â”‚
     â”‚             "data_start": self.data_start,                              â”‚
     â”‚             "data_end": self.data_end,                                  â”‚
     â”‚             "current_month_start": self.current_month_start,            â”‚
     â”‚             "current_month_end": self.current_month_end,                â”‚
     â”‚             "prev_month_start": self.prev_month_start,                  â”‚
     â”‚             "prev_month_end": self.prev_month_end                       â”‚
     â”‚         }                                                               â”‚
     â”‚                                                                         â”‚
     â”‚ Key Design: All time-based logic uses data_end from loaded data, not    â”‚
     â”‚ system clock                                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Actual Data Schema (from generate_data.py analysis)                     â”‚
     â”‚                                                                         â”‚
     â”‚ customers.csv fields:                                                   â”‚
     â”‚ - customer_id: "CUST-{0000}" (4-digit zero-padded)                      â”‚
     â”‚ - region: "north" | "south" | "east" | "west"                           â”‚
     â”‚ - signup_date: "YYYY-MM-DD" (180-730 days before end_date)              â”‚
     â”‚ - customer_segment: "new" (30%) | "regular" (50%) | "vip" (20%)         â”‚
     â”‚                                                                         â”‚
     â”‚ transactions.csv fields:                                                â”‚
     â”‚ - transaction_id: "TXN-{000000}" (6-digit zero-padded)                  â”‚
     â”‚ - customer_id: Foreign key to customers                                 â”‚
     â”‚ - transaction_date: "YYYY-MM-DD" (0-365 days before end_date, triangularâ”‚
     â”‚  weighted toward recent)                                                â”‚
     â”‚ - category: "electronics" | "clothing" | "home" | "grocery" | "sports"  â”‚
     â”‚ - product_name: "{Category} Item {1-20}"                                â”‚
     â”‚ - amount: Float (base_price Ã— random(0.5, 2.0) Ã— quantity)              â”‚
     â”‚ - quantity: Integer (1-3)                                               â”‚
     â”‚ - payment_method: "credit_card" | "debit_card" | "paypal" | "apple_pay" â”‚
     â”‚ - is_returned: Boolean (8% uniform probability)                         â”‚
     â”‚                                                                         â”‚
     â”‚ Base Prices:                                                            â”‚
     â”‚ - electronics: $150, clothing: $50, home: $40, grocery: $25, sports: $60â”‚
     â”‚                                                                         â”‚
     â”‚ Current Data Characteristics                                            â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”                                                                  â”‚
     â”‚ â”‚   Dimension   â”‚      Current        â”‚    Quality     â”‚        Notes   â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”‚               â”‚   Implementation    â”‚                â”‚                â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Customer      â”‚ 30% New, 50%        â”‚ âœ… Realistic   â”‚ Matches        â”‚
     â”‚ assignment  â”‚                                                           â”‚
     â”‚ â”‚ Segments      â”‚ Regular, 20% VIP    â”‚                â”‚ schema         â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Transactions  â”‚ Triangular(0, 365,  â”‚ âœ… Good        â”‚ Weighted towardâ”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”‚               â”‚ mode=60)            â”‚ seasonality    â”‚ recent 2 monthsâ”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Category Mix  â”‚ Uniform random      â”‚ âš ï¸ Acceptable  â”‚ Could add      â”‚
     â”‚ weights   â”‚                                                             â”‚
     â”‚ â”‚               â”‚ selection           â”‚                â”‚ for realism    â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Return Rates  â”‚ Uniform 8% across   â”‚ âš ï¸ Acceptable  â”‚ Simple but     â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”‚               â”‚ all                 â”‚                â”‚ sufficient for â”‚
     â”‚ demo â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Pricing       â”‚ Base Ã— random(0.5,  â”‚ âœ… Good        â”‚ Electronics    â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”‚               â”‚ 2.0)                â”‚ variance       â”‚ $75-$300 range â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Regional AOV  â”‚ No regional         â”‚ âš ï¸ Note        â”‚ All regions    â”‚
     â”‚ same    â”‚                                                               â”‚
     â”‚ â”‚               â”‚ variance            â”‚                â”‚ pricing        â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Date Range    â”‚ Last 12 months from â”‚ âœ… Appropriate â”‚ Need to fix    â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”‚               â”‚  end_date           â”‚                â”‚ datetime.now() â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Seed          â”‚ Fixed at 42         â”‚ âœ…             â”‚ Good for       â”‚
     â”‚ testing    â”‚                                                            â”‚
     â”‚ â”‚               â”‚                     â”‚ Reproducible   â”‚                â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Output        â”‚ Current directory   â”‚ âš ï¸ Note        â”‚ Creates files  â”‚
     â”‚ where â”‚                                                                 â”‚
     â”‚ â”‚ Location      â”‚ (root)              â”‚                â”‚  script runs   â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”˜                                                                  â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Why This Data is Sufficient                                             â”‚
     â”‚                                                                         â”‚
     â”‚ For Testing: Fixed seed enables reproducible tests                      â”‚
     â”‚                                                                         â”‚
     â”‚ For Demo: 5K transactions is enough to show all capabilities            â”‚
     â”‚                                                                         â”‚
     â”‚ For Realism: Sufficient data variety without overwhelming evaluators    â”‚
     â”‚                                                                         â”‚
     â”‚ For Assignment: Meets all required query types                          â”‚
     â”‚                                                                         â”‚
     â”‚ Tool Implementation Validation (Data Schema Alignment)                  â”‚
     â”‚                                                                         â”‚
     â”‚ Verification that each tool can be implemented with this data:          â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Tool 1: calculate_revenue_by_category()                              â”‚
     â”‚ - Needs: category, amount, is_returned, transaction_date âœ“ All present  â”‚
     â”‚ - Filters: is_returned=False to exclude returns                         â”‚
     â”‚ - Groups: By category                                                   â”‚
     â”‚ - Aggregates: SUM(amount), COUNT(*), AVG(amount)                        â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Tool 2: calculate_customer_ltv()                                     â”‚
     â”‚ - Needs: customer_id, amount, is_returned from transactions + region,   â”‚
     â”‚ customer_segment from customers âœ“                                       â”‚
     â”‚ - Join: transactions.customer_id = customers.customer_id                â”‚
     â”‚ - Filters: Optional by region, customer_segment                         â”‚
     â”‚ - Groups: By customer_id                                                â”‚
     â”‚ - Aggregates: SUM(amount), COUNT(*), with customer metadata             â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Tool 3: calculate_return_rate()                                      â”‚
     â”‚ - Needs: category, is_returned âœ“                                        â”‚
     â”‚ - Groups: By category                                                   â”‚
     â”‚ - Aggregates: COUNT(*), SUM(CASE WHEN is_returned THEN 1 ELSE 0)        â”‚
     â”‚ - Calculation: return_rate = returned_count / total_count               â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Tool 4: compare_regions()                                            â”‚
     â”‚ - Needs: region from customers + amount, is_returned, transaction_date  â”‚
     â”‚ from transactions âœ“                                                     â”‚
     â”‚ - Join: transactions.customer_id = customers.customer_id                â”‚
     â”‚ - Groups: By region                                                     â”‚
     â”‚ - Aggregates: SUM(amount), COUNT(DISTINCT customer_id), COUNT(*), returnâ”‚
     â”‚  rates                                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Tool 5: compare_time_periods()                                       â”‚
     â”‚ - Needs: transaction_date, amount, customer_id âœ“                        â”‚
     â”‚ - Filters: By date ranges                                               â”‚
     â”‚ - Aggregates: SUM(amount), COUNT(*), COUNT(DISTINCT customer_id) per    â”‚
     â”‚ period                                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… All required fields are present in the generated data schema         â”‚
     â”‚                                                                         â”‚
     â”‚ Expected Data Ranges & Validation                                       â”‚
     â”‚                                                                         â”‚
     â”‚ For 5000 transactions across 200 customers with seed=42:                â”‚
     â”‚ Metric: Total Revenue                                                   â”‚
     â”‚ Expected Range: ~$350K - $450K                                          â”‚
     â”‚ Notes: Based on base prices and 5K transactions                         â”‚
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
     â”‚ Metric: Avg Transaction Value                                           â”‚
     â”‚ Expected Range: ~$70 - $90                                              â”‚
     â”‚ Notes: Weighted average across categories                               â”‚
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
     â”‚ Metric: Transactions per Customer                                       â”‚
     â”‚ Expected Range: ~25 avg (power law)                                     â”‚
     â”‚ Notes: Some customers 1-2, others 100+                                  â”‚
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
     â”‚ Metric: Returns                                                         â”‚
     â”‚ Expected Range: ~400 transactions (8%)                                  â”‚
     â”‚ Notes: Uniform across categories                                        â”‚
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
     â”‚ Metric: Revenue per Category                                            â”‚
     â”‚ Expected Range: Electronics highest (~$150K), Grocery lowest (~$70K)    â”‚
     â”‚ Notes: Due to base price differences                                    â”‚
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
     â”‚ Metric: Customers per Region                                            â”‚
     â”‚ Expected Range: ~50 per region                                          â”‚
     â”‚ Notes: Uniform distribution                                             â”‚
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
     â”‚ Metric: Date Range                                                      â”‚
     â”‚ Expected Range: 2024-01-01 to 2024-12-31                                â”‚
     â”‚ Notes: After datetime.now() fix                                         â”‚
     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
     â”‚ Metric: Recent Transaction Density                                      â”‚
     â”‚ Expected Range: ~40% in last 2 months                                   â”‚
     â”‚ Notes: Due to triangular(mode=60)                                       â”‚
     â”‚ Validation Checks for Tools:                                            â”‚
     â”‚ - Revenue totals should be positive and in expected range               â”‚
     â”‚ - Category counts should be roughly equal (~1000 each)                  â”‚
     â”‚ - Region counts should be roughly equal (~50 customers, ~1250           â”‚
     â”‚ transactions)                                                           â”‚
     â”‚ - Return rates should be close to 8% for all categories                 â”‚
     â”‚ - Customer LTV rankings should show power law (top 20% customers drive  â”‚
     â”‚ ~80% revenue)                                                           â”‚
     â”‚ - All customer_ids should be valid (CUST-0000 to CUST-0199)             â”‚
     â”‚ - All dates should be within 2024-01-01 to 2024-12-31                   â”‚
     â”‚                                                                         â”‚
     â”‚ Implementation Strategy                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸ”´ CRITICAL: generate_data.py is immutable - must adapt TO it, not      â”‚
     â”‚ modify it                                                               â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸŸ¢ APPROACH: Dataset-anchored time logic (use data_end =                â”‚
     â”‚ max(transaction_date))                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸŸ¢ TESTING: Contract-based assertions (types, invariants, relationships)â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸŸ¢ INCREMENTAL: Step 1 only â†’ validate â†’ get approval â†’ proceed         â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Agent Configuration                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ OpenAI GPT-4 Setup                                                      â”‚
     â”‚                                                                         â”‚
     â”‚ # src/agent.py                                                          â”‚
     â”‚                                                                         â”‚
     â”‚ model = OpenAIModel(                                                    â”‚
     â”‚     client_args={"api_key": os.getenv("OPENAI_API_KEY")},               â”‚
     â”‚     model_id="gpt-4",  # or "gpt-4-turbo" for faster/cheaper            â”‚
     â”‚     params={                                                            â”‚
     â”‚         "temperature": 0.0,    # Deterministic responses                â”‚
     â”‚         "max_tokens": 2000,    # Sufficient for structured outputs      â”‚
     â”‚     }                                                                   â”‚
     â”‚ )                                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ agent = Agent(                                                          â”‚
     â”‚     model=model,                                                        â”‚
     â”‚     tools=[                                                             â”‚
     â”‚         calculate_revenue_by_category,                                  â”‚
     â”‚         calculate_customer_ltv,                                         â”‚
     â”‚         calculate_return_rate,                                          â”‚
     â”‚         compare_regions,                                                â”‚
     â”‚         compare_time_periods,                                           â”‚
     â”‚     ],                                                                  â”‚
     â”‚     system_message=(                                                    â”‚
     â”‚         "You are a business analytics assistant. "                      â”‚
     â”‚         "Use the provided tools to answer questions with specific       â”‚
     â”‚ numbers. "                                                              â”‚
     â”‚         "Format responses clearly using the structured data from tools."â”‚
     â”‚     )                                                                   â”‚
     â”‚ )                                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Critical Configuration Choices                                          â”‚
     â”‚                                                                         â”‚
     â”‚ Temperature = 0.0:                                                      â”‚
     â”‚ - Why: Analytics requires deterministic, factual answers                â”‚
     â”‚ - Trade-off: Less natural language variation, but consistency > style   â”‚
     â”‚                                                                         â”‚
     â”‚ GPT-4 vs GPT-4-Turbo:                                                   â”‚
     â”‚ - GPT-4: Better reasoning for complex tool selection (recommended)      â”‚
     â”‚ - GPT-4-Turbo: 2-3x faster, cheaper, still reliable for this use case   â”‚
     â”‚                                                                         â”‚
     â”‚ System Message:                                                         â”‚
     â”‚ - Guides behavior without restricting tool use                          â”‚
     â”‚ - Reinforces "use structured data" pattern                              â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Testing Strategy                                                        â”‚
     â”‚                                                                         â”‚
     â”‚ Three-Layer Testing Pyramid                                             â”‚
     â”‚                                                                         â”‚
     â”‚ Layer 1: Unit Tests (Tools)                                             â”‚
     â”‚                                                                         â”‚
     â”‚ File: tests/test_analytics.py                                           â”‚
     â”‚                                                                         â”‚
     â”‚ Test each analytical tool independently:                                â”‚
     â”‚ - Correct Pydantic model returned                                       â”‚
     â”‚ - Business logic accuracy (e.g., sum of categories = total revenue)     â”‚
     â”‚ - Date filtering works correctly                                        â”‚
     â”‚ - Rankings are properly sorted                                          â”‚
     â”‚ - Edge cases (no data, single transaction, etc.)                        â”‚
     â”‚                                                                         â”‚
     â”‚ Example:                                                                â”‚
     â”‚ def test_revenue_by_category_basic():                                   â”‚
     â”‚     result = calculate_revenue_by_category()                            â”‚
     â”‚     assert isinstance(result, RevenueByCategory)                        â”‚
     â”‚     assert result.total_revenue > 0                                     â”‚
     â”‚     assert len(result.categories) == 5  # All categories present        â”‚
     â”‚                                                                         â”‚
     â”‚     # Consistency check                                                 â”‚
     â”‚     calculated_total = sum(cat.total_revenue for cat in                 â”‚
     â”‚ result.categories)                                                      â”‚
     â”‚     assert abs(calculated_total - result.total_revenue) < 0.01          â”‚
     â”‚                                                                         â”‚
     â”‚ Layer 2: Integration Tests (Agent + Tools)                              â”‚
     â”‚                                                                         â”‚
     â”‚ File: tests/test_agent.py                                               â”‚
     â”‚                                                                         â”‚
     â”‚ Test agent behavior:                                                    â”‚
     â”‚ - Correct tool selection for each question type                         â”‚
     â”‚ - Response contains expected information                                â”‚
     â”‚ - No error messages in responses                                        â”‚
     â”‚ - Reasonable response length                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Example:                                                                â”‚
     â”‚ def test_agent_answers_revenue_question(agent):                         â”‚
     â”‚     response = agent("What is our total revenue by category?")          â”‚
     â”‚     assert "electronics" in response.lower()                            â”‚
     â”‚     assert any(char.isdigit() for char in response)                     â”‚
     â”‚                                                                         â”‚
     â”‚ Layer 3: End-to-End Validation                                          â”‚
     â”‚                                                                         â”‚
     â”‚ File: tests/test_agent.py                                               â”‚
     â”‚                                                                         â”‚
     â”‚ Validate answer accuracy:                                               â”‚
     â”‚ - Compare agent response against ground truth (direct tool call)        â”‚
     â”‚ - Ensure all 5 required questions are answerable                        â”‚
     â”‚ - Verify numerical accuracy within tolerance                            â”‚
     â”‚ - Check structured output format                                        â”‚
     â”‚                                                                         â”‚
     â”‚ Example:                                                                â”‚
     â”‚ def test_all_required_questions_answerable(agent):                      â”‚
     â”‚     required_questions = [                                              â”‚
     â”‚         "What is our total revenue by category?",                       â”‚
     â”‚         "Which customers have the highest lifetime value?",             â”‚
     â”‚         "What's the return rate by product category?",                  â”‚
     â”‚         "Compare performance across regions",                           â”‚
     â”‚         "How is this month performing compared to last month?",         â”‚
     â”‚     ]                                                                   â”‚
     â”‚                                                                         â”‚
     â”‚     for question in required_questions:                                 â”‚
     â”‚         response = agent(question)                                      â”‚
     â”‚         assert len(response) > 50  # Non-trivial response               â”‚
     â”‚         assert "error" not in response.lower()                          â”‚
     â”‚                                                                         â”‚
     â”‚ Running Tests                                                           â”‚
     â”‚                                                                         â”‚
     â”‚ pytest tests/ -v                     # Run all tests                    â”‚
     â”‚ pytest tests/test_analytics.py -v   # Test tools only                   â”‚
     â”‚ pytest --cov=src --cov-report=html   # With coverage report             â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Demo Script Design                                                      â”‚
     â”‚                                                                         â”‚
     â”‚ File: demo.py                                                           â”‚
     â”‚                                                                         â”‚
     â”‚ Strategic Question Selection                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Show 3 questions that demonstrate:                                      â”‚
     â”‚ 1. Different tool types: Aggregation, ranking, comparison               â”‚
     â”‚ 2. Structured outputs: Consistent formatting across question types      â”‚
     â”‚ 3. Business value: Actionable insights, not just data dumps             â”‚
     â”‚                                                                         â”‚
     â”‚ Recommended Questions                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Question 1: "What is our total revenue by category? Show me the         â”‚
     â”‚ breakdown."                                                             â”‚
     â”‚ - Demonstrates: Basic aggregation with calculate_revenue_by_category    â”‚
     â”‚ - Shows: Multi-field structured output (category, revenue, count, AOV)  â”‚
     â”‚ - Value: Core business metric every executive needs                     â”‚
     â”‚                                                                         â”‚
     â”‚ Question 2: "Which customers have the highest lifetime value? Show me   â”‚
     â”‚ the top 5."                                                             â”‚
     â”‚ - Demonstrates: Ranking capability with calculate_customer_ltv          â”‚
     â”‚ - Shows: Parameterized tool use (top_n argument)                        â”‚
     â”‚ - Value: Customer segmentation for targeted marketing                   â”‚
     â”‚                                                                         â”‚
     â”‚ Question 3: "Compare performance across all regions. Which region is    â”‚
     â”‚ performing best and why?"                                               â”‚
     â”‚ - Demonstrates: Complex multi-metric analysis with compare_regions      â”‚
     â”‚ - Shows: Comparative reasoning and insight generation                   â”‚
     â”‚ - Value: Strategic resource allocation decisions                        â”‚
     â”‚                                                                         â”‚
     â”‚ Expected Output Format                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ Each response should show:                                              â”‚
     â”‚ - Natural language summary                                              â”‚
     â”‚ - Structured data (tables/lists)                                        â”‚
     â”‚ - Specific numbers with context                                         â”‚
     â”‚ - Actionable insights                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Runtime: ~30 seconds total (demonstrates real LLM reasoning without     â”‚
     â”‚ lengthy wait)                                                           â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ STEP 1 Implementation (THIS STEP ONLY)                                  â”‚
     â”‚                                                                         â”‚
     â”‚ âš ï¸ CRITICAL: Implement ONLY Step 1, then STOP for approval before       â”‚
     â”‚ proceeding                                                              â”‚
     â”‚                                                                         â”‚
     â”‚ Step 1 Scope                                                            â”‚
     â”‚                                                                         â”‚
     â”‚ What to implement:                                                      â”‚
     â”‚ 1. Complete project skeleton (all directories, key files with minimal   â”‚
     â”‚ scaffolding)                                                            â”‚
     â”‚ 2. Data loading with dataset-anchored time logic                        â”‚
     â”‚ 3. ONE analytical tool only (calculate_revenue_by_category)             â”‚
     â”‚ 4. Dataset-agnostic unit tests for that tool                            â”‚
     â”‚ 5. Basic models for structured outputs                                  â”‚
     â”‚                                                                         â”‚
     â”‚ What NOT to implement yet:                                              â”‚
     â”‚ - Other 4 analytical tools (wait for approval)                          â”‚
     â”‚ - Agent configuration                                                   â”‚
     â”‚ - Demo script                                                           â”‚
     â”‚ - Integration tests with LLM                                            â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Step 1 Checklist                                                        â”‚
     â”‚                                                                         â”‚
     â”‚ 1.1 Project Skeleton (15 min)                                           â”‚
     â”‚                                                                         â”‚
     â”‚ Create complete directory structure reflecting final architecture:      â”‚
     â”‚                                                                         â”‚
     â”‚ mkdir -p src tests                                                      â”‚
     â”‚ touch src/__init__.py tests/__init__.py                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Create placeholder files (minimal scaffolding only):                    â”‚
     â”‚                                                                         â”‚
     â”‚ - src/config.py - Environment variable loading                          â”‚
     â”‚ - src/models.py - Pydantic models (RevenueByCategory only for Step 1)   â”‚
     â”‚ - src/data_loader.py - DataManager class (complete implementation)      â”‚
     â”‚ - src/analytics.py - Tool functions (ONE tool only)                     â”‚
     â”‚ - src/agent.py - Agent setup (placeholder/minimal for now)              â”‚
     â”‚ - tests/test_analytics.py - Unit tests (for ONE tool only)              â”‚
     â”‚ - tests/pytest.ini - Pytest configuration                               â”‚
     â”‚ - .env.example - API key template                                       â”‚
     â”‚ - README.md - Setup instructions skeleton                               â”‚
     â”‚                                                                         â”‚
     â”‚ Critical: All files should exist with correct structure, even if some   â”‚
     â”‚ are minimal placeholders                                                â”‚
     â”‚                                                                         â”‚
     â”‚ 1.2 Data Loading Implementation (20 min)                                â”‚
     â”‚                                                                         â”‚
     â”‚ File: src/data_loader.py                                                â”‚
     â”‚                                                                         â”‚
     â”‚ Implement complete DataManager class:                                   â”‚
     â”‚                                                                         â”‚
     â”‚ - Load transactions.csv and customers.csv from current directory        â”‚
     â”‚ - Convert date strings to pandas datetime                               â”‚
     â”‚ - Compute data_start and data_end from transactions                     â”‚
     â”‚ - Calculate current month and previous month boundaries                 â”‚
     â”‚ (dataset-anchored)                                                      â”‚
     â”‚ - Provide get_date_context() method                                     â”‚
     â”‚ - Add basic validation (check required columns exist)                   â”‚
     â”‚                                                                         â”‚
     â”‚ Test manually:                                                          â”‚
     â”‚ python generate_data.py  # Generate fresh data                          â”‚
     â”‚ python -c "from src.data_loader import DataManager; dm = DataManager(); â”‚
     â”‚ print(dm.get_date_context())"                                           â”‚
     â”‚                                                                         â”‚
     â”‚ 1.3 ONE Analytical Tool (30 min)                                        â”‚
     â”‚                                                                         â”‚
     â”‚ File: src/analytics.py                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ Implement ONLY calculate_revenue_by_category:                           â”‚
     â”‚                                                                         â”‚
     â”‚ - Use @tool decorator from strands                                      â”‚
     â”‚ - Accept optional start_date, end_date, categories parameters           â”‚
     â”‚ - Return Pydantic RevenueByCategory model                               â”‚
     â”‚ - Filter out returns (is_returned=False)                                â”‚
     â”‚ - Group by category, aggregate sum/count/avg                            â”‚
     â”‚ - Include comprehensive docstring for LLM                               â”‚
     â”‚ - Access DataManager singleton or pass as parameter                     â”‚
     â”‚                                                                         â”‚
     â”‚ File: src/models.py                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ Define ONLY the models needed for this tool:                            â”‚
     â”‚                                                                         â”‚
     â”‚ - CategoryRevenue (category, total_revenue, transaction_count,          â”‚
     â”‚ avg_transaction_value)                                                  â”‚
     â”‚ - RevenueByCategory (categories: List[CategoryRevenue], total_revenue,  â”‚
     â”‚ top_category)                                                           â”‚
     â”‚                                                                         â”‚
     â”‚ 1.4 Dataset-Agnostic Tests (25 min)                                     â”‚
     â”‚                                                                         â”‚
     â”‚ File: tests/test_analytics.py                                           â”‚
     â”‚                                                                         â”‚
     â”‚ Write contract-based tests (NO hardcoded values):                       â”‚
     â”‚                                                                         â”‚
     â”‚ - Test returns correct Pydantic model type                              â”‚
     â”‚ - Test all 5 categories present in output                               â”‚
     â”‚ - Test sum of category revenues equals total_revenue (invariant)        â”‚
     â”‚ - Test all revenue values > 0 (business logic)                          â”‚
     â”‚ - Test top_category is one of the 5 valid categories                    â”‚
     â”‚ - Test transaction counts are positive integers                         â”‚
     â”‚ - Test date filtering works (compare filtered vs unfiltered)            â”‚
     â”‚ - Test category filtering works                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Example assertion style:                                                â”‚
     â”‚ result = calculate_revenue_by_category()                                â”‚
     â”‚ assert isinstance(result, RevenueByCategory)  # Type contract           â”‚
     â”‚ assert len(result.categories) == 5  # Invariant                         â”‚
     â”‚ assert all(cat.total_revenue > 0 for cat in result.categories)  #       â”‚
     â”‚ Contract                                                                â”‚
     â”‚                                                                         â”‚
     â”‚ Run tests:                                                              â”‚
     â”‚ pytest tests/test_analytics.py -v                                       â”‚
     â”‚                                                                         â”‚
     â”‚ 1.5 Verification                                                        â”‚
     â”‚                                                                         â”‚
     â”‚ Before requesting approval, verify:                                     â”‚
     â”‚                                                                         â”‚
     â”‚ - Project structure complete and matches final architecture             â”‚
     â”‚ - python generate_data.py runs successfully                             â”‚
     â”‚ - Data loads without errors: python -c "from src.data_loader import     â”‚
     â”‚ DataManager; dm = DataManager()"                                        â”‚
     â”‚ - Tool executes: python -c "from src.analytics import                   â”‚
     â”‚ calculate_revenue_by_category; print(calculate_revenue_by_category())"  â”‚
     â”‚ - All tests pass: pytest tests/test_analytics.py -v                     â”‚
     â”‚ - No hardcoded dates or revenue values in tests                         â”‚
     â”‚ - Code is clean, documented, type-hinted                                â”‚
     â”‚                                                                         â”‚
     â”‚ Output for approval:                                                    â”‚
     â”‚ # Show structure                                                        â”‚
     â”‚ tree -L 2                                                               â”‚
     â”‚                                                                         â”‚
     â”‚ # Show test results                                                     â”‚
     â”‚ pytest tests/test_analytics.py -v                                       â”‚
     â”‚                                                                         â”‚
     â”‚ # Show tool output example                                              â”‚
     â”‚ python -c "from src.analytics import calculate_revenue_by_category;     â”‚
     â”‚ import json;                                                            â”‚
     â”‚ print(json.dumps(calculate_revenue_by_category().model_dump(),          â”‚
     â”‚ indent=2))"                                                             â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ â¸ï¸ STOP HERE - Wait for approval before implementing remaining tools    â”‚
     â”‚                                                                         â”‚
     â”‚ Total Step 1 Time: ~1.5 hours                                           â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Critical Files for Implementation                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Must-Have Files (Implementation Order)                                  â”‚
     â”‚                                                                         â”‚
     â”‚ 1. src/models.py - Pydantic schemas (7+ models)                         â”‚
     â”‚   - Foundation for all structured outputs                               â”‚
     â”‚   - Must include: 5 tool models + AgentResponse + ErrorResponse         â”‚
     â”‚   - Defines the API contract between tools and agent                    â”‚
     â”‚   - CRITICAL: AgentResponse ensures structured agent output             â”‚
     â”‚ 2. generate_data.py (root level) - Fix existing script                  â”‚
     â”‚   - âœ… Already exists at root level (aligns with assignment)            â”‚
     â”‚   - âŒ Needs modification: use fixed dates (not datetime.now())         â”‚
     â”‚   - âŒ Needs modification: accept --seed parameter for determinism      â”‚
     â”‚   - Creates the dataset (5K transactions, 200 customers)                â”‚
     â”‚ 3. src/analytics.py - 5+ analytical tools                               â”‚
     â”‚   - Core business logic - where questions get answered                  â”‚
     â”‚   - Most complex implementation work lives here                         â”‚
     â”‚   - NEW: Include optional filter parameters on tools                    â”‚
     â”‚   - NEW: Add explain_capabilities tool for error handling               â”‚
     â”‚ 4. src/agent.py - Strands Agent + OpenAI configuration                  â”‚
     â”‚   - Orchestration layer connecting LLM to tools                         â”‚
     â”‚   - Where architectural decisions materialize                           â”‚
     â”‚   - CRITICAL: Configure with output_schema=AgentResponse                â”‚
     â”‚   - CRITICAL: System message with boundaries                            â”‚
     â”‚ 5. demo.py - Demonstration script                                       â”‚
     â”‚   - First thing evaluators will run                                     â”‚
     â”‚   - Must showcase structured outputs clearly                            â”‚
     â”‚   - Should display AgentResponse format                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Supporting Files (Still Important)                                      â”‚
     â”‚                                                                         â”‚
     â”‚ - src/data_loader.py - DataManager class (CSV loading + date boundaries)â”‚
     â”‚ - src/config.py - Environment configuration                             â”‚
     â”‚ - tests/test_analytics.py - Tool unit tests (NO API KEY REQUIRED)       â”‚
     â”‚ - tests/test_agent_integration.py - Integration tests                   â”‚
     â”‚ (@requires_api_key)                                                     â”‚
     â”‚ - tests/pytest.ini - Skip API tests by default                          â”‚
     â”‚ - README.md - Documentation with design decisions                       â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Key Trade-offs & Design Decisions                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Decision 1: Structured Tools vs Code Generation                         â”‚
     â”‚                                                                         â”‚
     â”‚ Chosen: Structured tools with Pydantic outputs                          â”‚
     â”‚                                                                         â”‚
     â”‚ Why:                                                                    â”‚
     â”‚ - Reliability: Pre-defined tools reduce LLM error surface area          â”‚
     â”‚ - Testability: Known inputs/outputs enable comprehensive test coverage  â”‚
     â”‚ - Production-Ready: Structured outputs integrate cleanly with downstreamâ”‚
     â”‚  systems                                                                â”‚
     â”‚ - Interview Signal: Shows understanding of LLM limitations and          â”‚
     â”‚ mitigation strategies                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Trade-off: Less flexible than giving LLM arbitrary code execution, but  â”‚
     â”‚ acceptable for defined use cases                                        â”‚
     â”‚                                                                         â”‚
     â”‚ How to Explain: "For production systems, I prioritize reliability over  â”‚
     â”‚ flexibility. Structured tools give us testability and consistent        â”‚
     â”‚ outputs, which matter more than handling every conceivable question. If â”‚
     â”‚ we need new analytical capabilities later, we add new tools - it's      â”‚
     â”‚ maintainable and safe."                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Decision 2: Pandas vs SQL Backend                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Chosen: Pandas for analytical computations                              â”‚
     â”‚                                                                         â”‚
     â”‚ Why:                                                                    â”‚
     â”‚ - Data Scale: 10K rows easily fit in memory (< 5MB)                     â”‚
     â”‚ - Flexibility: Complex calculations (return rates, growth %) are cleanerâ”‚
     â”‚  in pandas                                                              â”‚
     â”‚ - Development Speed: Faster iteration than designing SQL schemas        â”‚
     â”‚ - User Preference: Aligns with stated preference for pandas             â”‚
     â”‚                                                                         â”‚
     â”‚ Trade-off: Won't scale to millions of rows, but appropriate for         â”‚
     â”‚ assignment scope                                                        â”‚
     â”‚                                                                         â”‚
     â”‚ How to Explain: "At 10K rows, pandas is the right tool - fast, flexible,â”‚
     â”‚  and familiar. If we needed to scale to millions of rows, I'd migrate toâ”‚
     â”‚  DuckDB or SQLite with minimal code changes since the tool layer        â”‚
     â”‚ abstracts the data access. Right-sizing the solution shows architecturalâ”‚
     â”‚  judgment."                                                             â”‚
     â”‚                                                                         â”‚
     â”‚ Decision 3: Tool Granularity (5 Focused Tools)                          â”‚
     â”‚                                                                         â”‚
     â”‚ Chosen: One tool per question type vs one generic "query_data" tool     â”‚
     â”‚                                                                         â”‚
     â”‚ Why:                                                                    â”‚
     â”‚ - LLM Success Rate: Simpler signatures = better tool selection accuracy â”‚
     â”‚ - Single Responsibility: Each tool has one clear, testable purpose      â”‚
     â”‚ - Explainability: Easy to trace which tool answered which question      â”‚
     â”‚ - Validation: Can validate outputs against ground truth per tool        â”‚
     â”‚                                                                         â”‚
     â”‚ Trade-off: More tools to maintain than a single flexible tool, but much â”‚
     â”‚ better UX                                                               â”‚
     â”‚                                                                         â”‚
     â”‚ How to Explain: "I optimized for LLM reliability. Five focused tools    â”‚
     â”‚ mean the model can't get confused about what tool to use - each has a   â”‚
     â”‚ clear semantic meaning. This is the difference between 'works in a demo'â”‚
     â”‚  and 'works in production at scale.'"                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Decision 4: Temperature = 0.0                                           â”‚
     â”‚                                                                         â”‚
     â”‚ Chosen: Fully deterministic responses                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Why:                                                                    â”‚
     â”‚ - Consistency: Same question yields same answer (critical for analytics)â”‚
     â”‚ - Testability: Reproducible outputs enable regression testing           â”‚
     â”‚ - Accuracy: No creativity needed for fact-based queries                 â”‚
     â”‚                                                                         â”‚
     â”‚ Trade-off: Less natural language variation in responses, but analytics  â”‚
     â”‚ values accuracy over style                                              â”‚
     â”‚                                                                         â”‚
     â”‚ How to Explain: "For analytics, consistency trumps creativity. Users    â”‚
     â”‚ need to trust that they'll get the same answer to the same question.    â”‚
     â”‚ Temperature=0.0 makes responses deterministic and testable - you can    â”‚
     â”‚ write assertions about agent behavior."                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Decision 5: CLI + Demo Script (Not Web UI)                              â”‚
     â”‚                                                                         â”‚
     â”‚ Chosen: Command-line interface with rich demo script                    â”‚
     â”‚                                                                         â”‚
     â”‚ Why:                                                                    â”‚
     â”‚ - Time Efficiency: Web UI would take 2+ hours to build properly         â”‚
     â”‚ - Focus: Demonstrates AI and data architecture skills, not frontend     â”‚
     â”‚ skills                                                                  â”‚
     â”‚ - Sufficient: Assignment requirements fully satisfied                   â”‚
     â”‚ - Interview Context: More time for deep technical discussion            â”‚
     â”‚                                                                         â”‚
     â”‚ Trade-off: Less visually impressive than a web UI, but shows deeper     â”‚
     â”‚ technical competence                                                    â”‚
     â”‚                                                                         â”‚
     â”‚ How to Explain: "I focused on the core AI architecture and data         â”‚
     â”‚ engineering challenge. For a Lead AI Engineer role, the value is in the â”‚
     â”‚ agent design, tool architecture, and data modeling - not in building    â”‚
     â”‚ React components. The demo script clearly showcases capabilities withoutâ”‚
     â”‚  distraction."                                                          â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Verification Plan (How to Test It Works)                                â”‚
     â”‚                                                                         â”‚
     â”‚ Step 1: Data Generation Verification                                    â”‚
     â”‚                                                                         â”‚
     â”‚ # Use root-level generate_data.py (per assignment instructions)         â”‚
     â”‚ python generate_data.py                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ # Verify output                                                         â”‚
     â”‚ ls -lh data/  # Should see transactions.csv (~400KB) and customers.csv  â”‚
     â”‚ (~15KB)                                                                 â”‚
     â”‚ head data/transactions.csv  # Inspect schema                            â”‚
     â”‚ wc -l data/transactions.csv  # Should be 5001 (5000 + header)           â”‚
     â”‚ wc -l data/customers.csv     # Should be 201 (200 + header)             â”‚
     â”‚                                                                         â”‚
     â”‚ # Verify date range                                                     â”‚
     â”‚ tail -1 data/transactions.csv  # Check dates are in 2024 range          â”‚
     â”‚                                                                         â”‚
     â”‚ Step 2: Tool Unit Tests                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ pytest tests/test_analytics.py -v                                       â”‚
     â”‚ # Should see all tests pass                                             â”‚
     â”‚ # Check: revenue calculations, LTV rankings, return rates               â”‚
     â”‚                                                                         â”‚
     â”‚ Step 3: Agent Integration Tests                                         â”‚
     â”‚                                                                         â”‚
     â”‚ pytest tests/test_agent.py -v                                           â”‚
     â”‚ # Validates agent can answer all 5 required questions                   â”‚
     â”‚ # May be slower (~30s) due to LLM calls                                 â”‚
     â”‚                                                                         â”‚
     â”‚ Step 4: Demo Script Execution                                           â”‚
     â”‚                                                                         â”‚
     â”‚ python demo.py                                                          â”‚
     â”‚ # Should output 3 questions with detailed, structured answers           â”‚
     â”‚ # Check: numerical data present, proper formatting, actionable insights â”‚
     â”‚                                                                         â”‚
     â”‚ Step 5: Manual Agent Testing                                            â”‚
     â”‚                                                                         â”‚
     â”‚ python -c "                                                             â”‚
     â”‚ from src.agent import create_business_agent                             â”‚
     â”‚ agent = create_business_agent()                                         â”‚
     â”‚ response = agent('What is our total revenue by category?')              â”‚
     â”‚ print(response)                                                         â”‚
     â”‚ "                                                                       â”‚
     â”‚ # Inspect output quality manually                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Success Criteria                                                        â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Data: 10K transactions, 500 customers, realistic distributions       â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Tests: All unit and integration tests pass                           â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Demo: Script runs successfully, shows structured outputs             â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Accuracy: Agent answers match ground truth from direct tool calls    â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Quality: Responses are formatted, contain specific numbers, provide  â”‚
     â”‚ insights                                                                â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Post-Implementation: How to Explain Your Design                         â”‚
     â”‚                                                                         â”‚
     â”‚ For Technical Interview Discussion                                      â”‚
     â”‚                                                                         â”‚
     â”‚ If asked "Why this architecture?":                                      â”‚
     â”‚ - "I chose a three-layer architecture to separate concerns: data access,â”‚
     â”‚  business logic, and AI orchestration. This makes testing easier since  â”‚
     â”‚ each layer can be mocked independently."                                â”‚
     â”‚                                                                         â”‚
     â”‚ If asked "Why structured tools instead of letting the LLM write pandas  â”‚
     â”‚ code?":                                                                 â”‚
     â”‚ - "Reliability and testability. Pre-defined tools have known            â”‚
     â”‚ input/output contracts, which means I can write comprehensive tests and â”‚
     â”‚ guarantee output format. In production, you need predictability."       â”‚
     â”‚                                                                         â”‚
     â”‚ If asked "How would you scale this to 100M rows?":                      â”‚
     â”‚ - "Migrate the data layer to DuckDB or SQLite without changing the tool â”‚
     â”‚ signatures. The abstraction layer means tools don't care about the      â”‚
     â”‚ underlying storage. I'd also add result caching and potentially         â”‚
     â”‚ pre-aggregate common queries."                                          â”‚
     â”‚                                                                         â”‚
     â”‚ If asked "How do you ensure answer correctness?":                       â”‚
     â”‚ - "Three-layer testing: unit tests validate tool logic, integration     â”‚
     â”‚ tests ensure agent selects correct tools, and E2E tests compare agent   â”‚
     â”‚ answers against ground truth. I also seeded the random generator so dataâ”‚
     â”‚  is reproducible across test runs."                                     â”‚
     â”‚                                                                         â”‚
     â”‚ If asked "What would you add next?":                                    â”‚
     â”‚ - "Three priorities: (1) conversation memory for follow-up questions,   â”‚
     â”‚ (2) caching layer for repeated queries, (3) observability with          â”‚
     â”‚ request/response logging. These move it from demo to production-grade." â”‚
     â”‚                                                                         â”‚
     â”‚ For Design Trade-offs Discussion                                        â”‚
     â”‚                                                                         â”‚
     â”‚ Key points to emphasize:                                                â”‚
     â”‚ 1. Right-sizing: Used pandas for 10K rows (appropriate scale) rather    â”‚
     â”‚ than over-engineering with a full database                              â”‚
     â”‚ 2. Reliability: Chose structured tools over flexible code generation    â”‚
     â”‚ because production systems need predictability                          â”‚
     â”‚ 3. Testing: Architecture enables comprehensive testing at every layer   â”‚
     â”‚ 4. Maintainability: Clear separation of concerns makes debugging and    â”‚
     â”‚ extension straightforward                                               â”‚
     â”‚ 5. Time Management: Focused on core AI/data challenges rather than      â”‚
     â”‚ peripheral features (UI, auth, etc.)                                    â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Extensions for Follow-Up Discussion                                     â”‚
     â”‚                                                                         â”‚
     â”‚ If asked "How would you extend this?", be prepared to discuss:          â”‚
     â”‚                                                                         â”‚
     â”‚ Near-term Enhancements (1-2 weeks)                                      â”‚
     â”‚                                                                         â”‚
     â”‚ - Conversation Memory: Use Strands conversation history to handle "tell â”‚
     â”‚ me more" follow-ups                                                     â”‚
     â”‚ - Query Optimization: Add caching layer (Redis/in-memory) for repeated  â”‚
     â”‚ queries                                                                 â”‚
     â”‚ - Additional Analytics: Churn prediction, product recommendations,      â”‚
     â”‚ cohort analysis                                                         â”‚
     â”‚ - Error Handling: Comprehensive try-catch with fallback behaviors       â”‚
     â”‚                                                                         â”‚
     â”‚ Production Hardening (1 month)                                          â”‚
     â”‚                                                                         â”‚
     â”‚ - Observability: Logging, metrics, request tracing                      â”‚
     â”‚ - Scale: Migrate to DuckDB/SQLite for multi-GB datasets                 â”‚
     â”‚ - Security: Input validation, rate limiting, API key rotation           â”‚
     â”‚ - Deployment: Containerize with Docker, add health checks               â”‚
     â”‚                                                                         â”‚
     â”‚ Advanced Features (2-3 months)                                          â”‚
     â”‚                                                                         â”‚
     â”‚ - Multi-Agent System: Separate agents for customer, product, finance    â”‚
     â”‚ domains                                                                 â”‚
     â”‚ - Agentic Reasoning: Let agent decide which data to join/filter before  â”‚
     â”‚ analysis                                                                â”‚
     â”‚ - Natural Language to SQL: Let LLM generate complex queries for ad-hoc  â”‚
     â”‚ questions                                                               â”‚
     â”‚ - Scheduled Reports: Automated daily/weekly analytics emails            â”‚
     â”‚                                                                         â”‚
     â”‚ Integration Points                                                      â”‚
     â”‚                                                                         â”‚
     â”‚ - REST API: FastAPI wrapper for web apps                                â”‚
     â”‚ - Slack Bot: Post analytics to channels on schedule or on-demand        â”‚
     â”‚ - Dashboard: Streamlit/Dash for visual exploration                      â”‚
     â”‚ - Data Warehouse: Connect to Snowflake/BigQuery for real data           â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Dependencies & Environment                                              â”‚
     â”‚                                                                         â”‚
     â”‚ Required Packages (Already Installed)                                   â”‚
     â”‚                                                                         â”‚
     â”‚ - strands_agents - Main SDK                                             â”‚
     â”‚ - pandas - Data manipulation                                            â”‚
     â”‚ - numpy - Numerical operations                                          â”‚
     â”‚ - pydantic - Data validation                                            â”‚
     â”‚ - python-dotenv - Environment variables                                 â”‚
     â”‚ - openai (via Strands) - LLM provider                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Environment Variables                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Create .env file:                                                       â”‚
     â”‚ OPENAI_API_KEY=sk-...your-key-here...                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Python Version                                                          â”‚
     â”‚                                                                         â”‚
     â”‚ - Minimum: Python 3.10                                                  â”‚
     â”‚ - Recommended: Python 3.11+                                             â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Final Checklist Before Submission                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Code Quality                                                            â”‚
     â”‚                                                                         â”‚
     â”‚ - All functions have docstrings                                         â”‚
     â”‚ - Type hints on function signatures                                     â”‚
     â”‚ - No hardcoded values (use config)                                      â”‚
     â”‚ - Error handling for file I/O and LLM calls                             â”‚
     â”‚ - Consistent code style (black/ruff formatted)                          â”‚
     â”‚                                                                         â”‚
     â”‚ Testing                                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ - All tests pass: pytest tests/ -v                                      â”‚
     â”‚ - Test coverage > 80%: pytest --cov=src                                 â”‚
     â”‚ - Demo script runs successfully: python demo.py                         â”‚
     â”‚                                                                         â”‚
     â”‚ Documentation                                                           â”‚
     â”‚                                                                         â”‚
     â”‚ - README.md has clear setup instructions                                â”‚
     â”‚ - Architecture decisions explained                                      â”‚
     â”‚ - Design trade-offs documented                                          â”‚
     â”‚ - Run instructions for demo and tests                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Deliverables                                                            â”‚
     â”‚                                                                         â”‚
     â”‚ - GitHub repo accessible to evaluator                                   â”‚
     â”‚ - .env.example included (not .env with actual keys)                     â”‚
     â”‚ - Clear commit history                                                  â”‚
     â”‚ - All required files present                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Verification                                                            â”‚
     â”‚                                                                         â”‚
     â”‚ - Fresh clone in new directory works                                    â”‚
     â”‚ - Can run from scratch: pip install -r requirements.txt                 â”‚
     â”‚ - Data generation works: python src/data_generator.py                   â”‚
     â”‚ - Demo runs end-to-end: python demo.py                                  â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ Summary: Why This Plan Works                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Demonstrates Technical Excellence                                       â”‚
     â”‚                                                                         â”‚
     â”‚ - Architecture: Clean separation of concerns, testable layers           â”‚
     â”‚ - LLM Expertise: Tool design optimized for GPT-4 reliability            â”‚
     â”‚ - Data Engineering: Realistic data generation with proper distributions â”‚
     â”‚ - Software Engineering: Comprehensive testing, type safety,             â”‚
     â”‚ documentation                                                           â”‚
     â”‚                                                                         â”‚
     â”‚ Practical Implementation                                                â”‚
     â”‚                                                                         â”‚
     â”‚ - Time: 2-3 hours for full implementation                               â”‚
     â”‚ - Scope: Right-sized for assignment (not over-engineered)               â”‚
     â”‚ - Clarity: Easy to explain technical decisions                          â”‚
     â”‚                                                                         â”‚
     â”‚ Production-Ready Feel                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ - Structured Outputs: Pydantic validation guarantees consistency        â”‚
     â”‚ - Testing: Three-layer coverage (unit, integration, E2E)                â”‚
     â”‚ - Maintainability: Clear code organization, good separation             â”‚
     â”‚                                                                         â”‚
     â”‚ Interview Signals                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ - Systems Thinking: Understands how pieces fit together                 â”‚
     â”‚ - Trade-off Analysis: Can justify architectural decisions               â”‚
     â”‚ - Pragmatism: Right tool for the job, not over-engineering              â”‚
     â”‚ - Production Mindset: Thinks about testing, scaling, maintaining        â”‚
     â”‚                                                                         â”‚
     â”‚ This plan positions you to deliver a portfolio-quality implementation   â”‚
     â”‚ that showcases Lead AI Engineer level thinking: not just making         â”‚
     â”‚ something work, but architecting a maintainable, testable,              â”‚
     â”‚ production-grade system that happens to use AI.                         â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 10. Critical Design Review & Risk Analysis                              â”‚
     â”‚                                                                         â”‚
     â”‚ This section provides an honest assessment of design risks, alignment   â”‚
     â”‚ issues, and concrete mitigation strategies.                             â”‚
     â”‚                                                                         â”‚
     â”‚ 10.1 Alignment With Assignment Requirements                             â”‚
     â”‚                                                                         â”‚
     â”‚ CRITICAL ISSUE #1: Data Generation Mismatch                             â”‚
     â”‚                                                                         â”‚
     â”‚ Problem:                                                                â”‚
     â”‚ - âœ… Assignment expects: python generate_data.py at root level          â”‚
     â”‚ - âœ… Root-level generate_data.py already exists                         â”‚
     â”‚ - âŒ Plan specifies: src/data_generator.py with different parameters    â”‚
     â”‚ - âŒ Existing generator creates 5K transactions / 200 customers         â”‚
     â”‚ - âŒ Plan assumes 10K transactions / 500 customers                      â”‚
     â”‚ - âŒ Existing generator uses datetime.now() (non-deterministic)         â”‚
     â”‚                                                                         â”‚
     â”‚ Risk Level: HIGH - Evaluators will run existing script and get differentâ”‚
     â”‚  data than expected                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy:                                                    â”‚
     â”‚ # DECISION: Use existing root-level generate_data.py as-is              â”‚
     â”‚ # - Aligns with assignment instructions perfectly                       â”‚
     â”‚ # - Already functional and tested                                       â”‚
     â”‚ # - Modify to accept command-line arguments for flexibility:            â”‚
     â”‚                                                                         â”‚
     â”‚ python generate_data.py              # Default: 5K txns, 200 customers  â”‚
     â”‚ python generate_data.py --large      # Optional: 10K txns, 500 customersâ”‚
     â”‚ python generate_data.py --seed 42    # Fix seed for determinism         â”‚
     â”‚                                                                         â”‚
     â”‚ Plan Update Required:                                                   â”‚
     â”‚ 1. Remove src/data_generator.py from plan                               â”‚
     â”‚ 2. Update all references to use root-level generate_data.py             â”‚
     â”‚ 3. Adjust tool implementations for 5K/200 scale (not 10K/500)           â”‚
     â”‚ 4. Add seed parameter for test reproducibility                          â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 10.2 Output Contract & Consistency                                      â”‚
     â”‚                                                                         â”‚
     â”‚ CRITICAL ISSUE #2: Agent Returns Free-Form Text, Not Structured Data    â”‚
     â”‚                                                                         â”‚
     â”‚ Problem:                                                                â”‚
     â”‚ - âœ… Tools return structured Pydantic models (good!)                    â”‚
     â”‚ - âŒ Agent wraps tool outputs in natural language (bad!)                â”‚
     â”‚ - âŒ Assignment says: "Return structured, consistent responses (not     â”‚
     â”‚ free-form text)"                                                        â”‚
     â”‚ - âŒ Current design: Agent returns string like "The revenue by category â”‚
     â”‚ is..."                                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ Example of the Problem:                                                 â”‚
     â”‚ # Tool returns structured data:                                         â”‚
     â”‚ RevenueByCategory(                                                      â”‚
     â”‚     categories=[...],                                                   â”‚
     â”‚     total_revenue=1500000.00,                                           â”‚
     â”‚     top_category="electronics"                                          â”‚
     â”‚ )                                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ # But agent returns:                                                    â”‚
     â”‚ "Based on the analysis, our total revenue by category shows that        â”‚
     â”‚ electronics leads with $450K, followed by clothing at $375K..."         â”‚
     â”‚                                                                         â”‚
     â”‚ Why This Matters:                                                       â”‚
     â”‚ - Evaluators can't programmatically validate responses                  â”‚
     â”‚ - Each question gets different formatting                               â”‚
     â”‚ - Doesn't meet "structured, consistent" requirement                     â”‚
     â”‚ - Hard to use agent in production systems                               â”‚
     â”‚                                                                         â”‚
     â”‚ Risk Level: HIGH - Core requirement violation                           â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy #1: Structured Output Wrapper (RECOMMENDED)         â”‚
     â”‚                                                                         â”‚
     â”‚ # Add unified response schema                                           â”‚
     â”‚ class AgentResponse(BaseModel):                                         â”‚
     â”‚     """Unified response format for all agent queries."""                â”‚
     â”‚     question: str                                                       â”‚
     â”‚     answer_summary: str                                                 â”‚
     â”‚     data: Union[                                                        â”‚
     â”‚         RevenueByCategory,                                              â”‚
     â”‚         CustomerLifetimeValue,                                          â”‚
     â”‚         ReturnRateByCategory,                                           â”‚
     â”‚         RegionPerformance,                                              â”‚
     â”‚         PeriodComparison                                                â”‚
     â”‚     ]                                                                   â”‚
     â”‚     metadata: dict = Field(default_factory=dict)                        â”‚
     â”‚                                                                         â”‚
     â”‚ # Configure agent to return structured output                           â”‚
     â”‚ agent = Agent(                                                          â”‚
     â”‚     model=model,                                                        â”‚
     â”‚     tools=[...],                                                        â”‚
     â”‚     output_schema=AgentResponse,  # Force structured responses          â”‚
     â”‚ )                                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy #2: Tool Output Pass-Through (SIMPLER)              â”‚
     â”‚                                                                         â”‚
     â”‚ # Agent system message:                                                 â”‚
     â”‚ "When using tools, return ONLY the tool output as JSON.                 â”‚
     â”‚ Do not add natural language wrappers.                                   â”‚
     â”‚ The tool output is already structured and complete."                    â”‚
     â”‚                                                                         â”‚
     â”‚ # Then parse agent response as JSON and validate against tool schemas   â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy #3: Post-Process Agent Response (FALLBACK)          â”‚
     â”‚                                                                         â”‚
     â”‚ # If agent must return natural language + data:                         â”‚
     â”‚ class AgentResponse(BaseModel):                                         â”‚
     â”‚     summary: str                                                        â”‚
     â”‚     structured_data: dict                                               â”‚
     â”‚     tool_used: str                                                      â”‚
     â”‚                                                                         â”‚
     â”‚ def ask_agent(question: str) -> AgentResponse:                          â”‚
     â”‚     """Wrapper that extracts structured data from agent response."""    â”‚
     â”‚     response = agent(question)                                          â”‚
     â”‚     # Parse response to extract tool output                             â”‚
     â”‚     # Return both summary and structured data                           â”‚
     â”‚                                                                         â”‚
     â”‚ Plan Update Required:                                                   â”‚
     â”‚ 1. Add AgentResponse model to models.py                                 â”‚
     â”‚ 2. Configure agent with output schema OR adjust system message          â”‚
     â”‚ 3. Update demo script to show structured output                         â”‚
     â”‚ 4. Update tests to validate response structure                          â”‚
     â”‚ 5. Add section to README explaining output format                       â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 10.3 Flexibility Beyond the Exact Questions                             â”‚
     â”‚                                                                         â”‚
     â”‚ ISSUE #3: Rigid Tool Design Limits Question Variations                  â”‚
     â”‚                                                                         â”‚
     â”‚ Problem:                                                                â”‚
     â”‚ - âŒ Tools are narrowly scoped to 5 specific questions                  â”‚
     â”‚ - âŒ Evaluators may ask variations:                                     â”‚
     â”‚   - "What's revenue for electronics only?" (subset of Tool 1)           â”‚
     â”‚   - "Compare this week vs last week" (variation of Tool 5)              â”‚
     â”‚   - "Which region has the best return rate?" (combines Tool 3 + 4)      â”‚
     â”‚   - "Show me top 3 customers in the North region" (filtered Tool 2)     â”‚
     â”‚                                                                         â”‚
     â”‚ Risk Level: MEDIUM - May fail on reasonable question variations         â”‚
     â”‚                                                                         â”‚
     â”‚ Current Tool Design:                                                    â”‚
     â”‚ # Tool 1: Returns ALL categories, no filtering                          â”‚
     â”‚ def calculate_revenue_by_category() -> RevenueByCategory:               â”‚
     â”‚     # No category parameter - can't filter                              â”‚
     â”‚                                                                         â”‚
     â”‚ # Tool 2: Returns top_n globally, no region filter                      â”‚
     â”‚ def calculate_customer_ltv(top_n: int = 10) -> CustomerLifetimeValue:   â”‚
     â”‚     # No region parameter                                               â”‚
     â”‚                                                                         â”‚
     â”‚ # Tool 5: Requires exact date strings                                   â”‚
     â”‚ def compare_time_periods(                                               â”‚
     â”‚     current_start: str,                                                 â”‚
     â”‚     current_end: str,                                                   â”‚
     â”‚     previous_start: str,                                                â”‚
     â”‚     previous_end: str                                                   â”‚
     â”‚ ) -> PeriodComparison:                                                  â”‚
     â”‚     # LLM must calculate dates from "this month" -> risk of errors      â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy:                                                    â”‚
     â”‚                                                                         â”‚
     â”‚ Option A: Add Optional Filters to Tools (RECOMMENDED)                   â”‚
     â”‚                                                                         â”‚
     â”‚ def calculate_revenue_by_category(                                      â”‚
     â”‚     start_date: Optional[str] = None,                                   â”‚
     â”‚     end_date: Optional[str] = None,                                     â”‚
     â”‚     categories: Optional[List[str]] = None,  # NEW: filter specific     â”‚
     â”‚ categories                                                              â”‚
     â”‚ ) -> RevenueByCategory:                                                 â”‚
     â”‚     """More flexible - can answer subsets"""                            â”‚
     â”‚                                                                         â”‚
     â”‚ def calculate_customer_ltv(                                             â”‚
     â”‚     top_n: int = 10,                                                    â”‚
     â”‚     region: Optional[str] = None,  # NEW: filter by region              â”‚
     â”‚     segment: Optional[str] = None,  # NEW: filter by segment            â”‚
     â”‚ ) -> CustomerLifetimeValue:                                             â”‚
     â”‚     """Can answer "top customers in North" """                          â”‚
     â”‚                                                                         â”‚
     â”‚ def compare_time_periods(                                               â”‚
     â”‚     period_label: str = "custom",  # "this_month_vs_last" or "Q4_vs_Q3" â”‚
     â”‚     current_start: Optional[str] = None,                                â”‚
     â”‚     current_end: Optional[str] = None,                                  â”‚
     â”‚     previous_start: Optional[str] = None,                               â”‚
     â”‚     previous_end: Optional[str] = None                                  â”‚
     â”‚ ) -> PeriodComparison:                                                  â”‚
     â”‚     """If period_label provided, calculate dates automatically"""       â”‚
     â”‚                                                                         â”‚
     â”‚ Option B: Add Generic Query Tool (BACKUP)                               â”‚
     â”‚                                                                         â”‚
     â”‚ def query_data(                                                         â”‚
     â”‚     metric: str,  # "revenue", "ltv", "return_rate"                     â”‚
     â”‚     group_by: Optional[str] = None,  # "category", "region"             â”‚
     â”‚     filters: Optional[dict] = None,                                     â”‚
     â”‚ ) -> dict:                                                              â”‚
     â”‚     """Generic fallback for unexpected questions"""                     â”‚
     â”‚                                                                         â”‚
     â”‚ Trade-off Analysis:                                                     â”‚
     â”‚ - Option A: More parameters make tools slightly harder to use, but much â”‚
     â”‚ more flexible                                                           â”‚
     â”‚ - Option B: Adds complexity and reduces structure guarantees            â”‚
     â”‚ - Recommendation: Use Option A for primary tools, add Option B as       â”‚
     â”‚ fallback                                                                â”‚
     â”‚                                                                         â”‚
     â”‚ Plan Update Required:                                                   â”‚
     â”‚ 1. Add optional parameters to tool signatures                           â”‚
     â”‚ 2. Update tool docstrings with examples of variations                   â”‚
     â”‚ 3. Test that LLM can correctly use optional parameters                  â”‚
     â”‚ 4. Add tests for question variations                                    â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 10.4 Handling Unsupported or Ambiguous Questions                        â”‚
     â”‚                                                                         â”‚
     â”‚ ISSUE #4: No Error Handling Strategy                                    â”‚
     â”‚                                                                         â”‚
     â”‚ Problem:                                                                â”‚
     â”‚ - âŒ Plan doesn't address what happens when:                            â”‚
     â”‚   - Question can't be answered with available tools                     â”‚
     â”‚   - Required data doesn't exist ("What's our profit margin?")           â”‚
     â”‚   - Question is ambiguous ("What's trending?")                          â”‚
     â”‚   - Data is empty or invalid                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Risk Level: MEDIUM - Unprofessional behavior for unsupported queries    â”‚
     â”‚                                                                         â”‚
     â”‚ Current Behavior (undefined):                                           â”‚
     â”‚ - Agent might hallucinate an answer                                     â”‚
     â”‚ - Agent might try to use wrong tool                                     â”‚
     â”‚ - Agent might return confusing message                                  â”‚
     â”‚ - No structured error response                                          â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy:                                                    â”‚
     â”‚                                                                         â”‚
     â”‚ 1. Add Error Response Model:                                            â”‚
     â”‚ class ErrorResponse(BaseModel):                                         â”‚
     â”‚     """Structured error response when query cannot be answered."""      â”‚
     â”‚     error: bool = True                                                  â”‚
     â”‚     error_type: str  # "unsupported_query", "missing_data", "ambiguous" â”‚
     â”‚     message: str                                                        â”‚
     â”‚     suggestions: List[str] = []  # What questions CAN be answered       â”‚
     â”‚                                                                         â”‚
     â”‚ # Update AgentResponse to handle errors                                 â”‚
     â”‚ class AgentResponse(BaseModel):                                         â”‚
     â”‚     success: bool                                                       â”‚
     â”‚     question: str                                                       â”‚
     â”‚     data: Optional[Union[...]] = None                                   â”‚
     â”‚     error: Optional[ErrorResponse] = None                               â”‚
     â”‚                                                                         â”‚
     â”‚ 2. Update System Message:                                               â”‚
     â”‚ system_message = """                                                    â”‚
     â”‚ You are a business analytics assistant with access to specific tools.   â”‚
     â”‚                                                                         â”‚
     â”‚ IMPORTANT: You can ONLY answer questions using the available tools:     â”‚
     â”‚ 1. Revenue analysis by category                                         â”‚
     â”‚ 2. Customer lifetime value rankings                                     â”‚
     â”‚ 3. Return rates by category                                             â”‚
     â”‚ 4. Regional performance comparison                                      â”‚
     â”‚ 5. Time period comparisons                                              â”‚
     â”‚                                                                         â”‚
     â”‚ If a question cannot be answered with these tools:                      â”‚
     â”‚ 1. Explain what data/tools are available                                â”‚
     â”‚ 2. Suggest similar questions that CAN be answered                       â”‚
     â”‚ 3. Do NOT make up answers or use external knowledge                     â”‚
     â”‚                                                                         â”‚
     â”‚ If data is missing or a query fails, return a structured error response.â”‚
     â”‚ """                                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ 3. Add Fallback Tool:                                                   â”‚
     â”‚ @tool                                                                   â”‚
     â”‚ def explain_capabilities() -> dict:                                     â”‚
     â”‚     """                                                                 â”‚
     â”‚     Explains what questions the agent can answer.                       â”‚
     â”‚     Use this when user asks something outside available tools.          â”‚
     â”‚     """                                                                 â”‚
     â”‚     return {                                                            â”‚
     â”‚         "available_analyses": [                                         â”‚
     â”‚             "Revenue by category",                                      â”‚
     â”‚             "Customer lifetime value rankings",                         â”‚
     â”‚             "Return rates by category",                                 â”‚
     â”‚             "Regional performance",                                     â”‚
     â”‚             "Time period comparisons"                                   â”‚
     â”‚         ],                                                              â”‚
     â”‚         "example_questions": [                                          â”‚
     â”‚             "What is our total revenue by category?",                   â”‚
     â”‚             "Which customers have the highest lifetime value?",         â”‚
     â”‚             # ... etc                                                   â”‚
     â”‚         ]                                                               â”‚
     â”‚     }                                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ Plan Update Required:                                                   â”‚
     â”‚ 1. Add ErrorResponse model to models.py                                 â”‚
     â”‚ 2. Add explain_capabilities tool to analytics.py                        â”‚
     â”‚ 3. Update system message with boundaries                                â”‚
     â”‚ 4. Add tests for unsupported questions                                  â”‚
     â”‚ 5. Document expected behavior in README                                 â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 10.5 Time-Based Logic & Determinism                                     â”‚
     â”‚                                                                         â”‚
     â”‚ ISSUE #5: Non-Deterministic Date Handling                               â”‚
     â”‚                                                                         â”‚
     â”‚ Problem:                                                                â”‚
     â”‚ - âŒ Existing generate_data.py uses datetime.now() (changes daily)      â”‚
     â”‚ - âŒ Tool 5 question: "How is this month performing compared to last    â”‚
     â”‚ month?"                                                                 â”‚
     â”‚ - âŒ Who calculates what "this month" means?                            â”‚
     â”‚ - âŒ Data spans last 12 months from TODAY - changes every run           â”‚
     â”‚ - âŒ Tests won't be reproducible across different days                  â”‚
     â”‚                                                                         â”‚
     â”‚ Example Failure Scenario:                                               â”‚
     â”‚ # On January 12, 2026:                                                  â”‚
     â”‚ generate_data.py creates data from Jan 12, 2025 to Jan 12, 2026         â”‚
     â”‚ Agent asked: "Compare this month to last month"                         â”‚
     â”‚ LLM calculates: Jan 2026 vs Dec 2025                                    â”‚
     â”‚ Tests pass âœ“                                                            â”‚
     â”‚                                                                         â”‚
     â”‚ # On February 1, 2026 (evaluator runs it):                              â”‚
     â”‚ generate_data.py creates data from Feb 1, 2025 to Feb 1, 2026           â”‚
     â”‚ Agent asked: "Compare this month to last month"                         â”‚
     â”‚ LLM calculates: Feb 2026 vs Jan 2026                                    â”‚
     â”‚ Partial month data, different results                                   â”‚
     â”‚ Tests fail âœ—                                                            â”‚
     â”‚                                                                         â”‚
     â”‚ Risk Level: HIGH - Non-reproducible results, test failures              â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy:                                                    â”‚
     â”‚                                                                         â”‚
     â”‚ 1. Fix Data Generation to Use Static Dates:                             â”‚
     â”‚ # In generate_data.py:                                                  â”‚
     â”‚ # BEFORE (non-deterministic):                                           â”‚
     â”‚ today = datetime.now().date()                                           â”‚
     â”‚                                                                         â”‚
     â”‚ # AFTER (deterministic):                                                â”‚
     â”‚ today = datetime(2024, 12, 31).date()  # Fixed end date                 â”‚
     â”‚ # Or accept as parameter:                                               â”‚
     â”‚ today = datetime.strptime(args.end_date, "%Y-%m-%d").date()             â”‚
     â”‚                                                                         â”‚
     â”‚ 2. Add Date Context to Data Manager:                                    â”‚
     â”‚ class DataManager:                                                      â”‚
     â”‚     def __init__(self):                                                 â”‚
     â”‚         self.transactions = self.load_transactions()                    â”‚
     â”‚         self.customers = self.load_customers()                          â”‚
     â”‚                                                                         â”‚
     â”‚         # Calculate data boundaries                                     â”‚
     â”‚         self.data_start = self.transactions['transaction_date'].min()   â”‚
     â”‚         self.data_end = self.transactions['transaction_date'].max()     â”‚
     â”‚                                                                         â”‚
     â”‚     def get_date_range(self) -> dict:                                   â”‚
     â”‚         """Return available date range for time-based queries."""       â”‚
     â”‚         return {                                                        â”‚
     â”‚             "start": self.data_start,                                   â”‚
     â”‚             "end": self.data_end,                                       â”‚
     â”‚             "full_months": self.calculate_full_months()                 â”‚
     â”‚         }                                                               â”‚
     â”‚                                                                         â”‚
     â”‚ 3. Make Time Period Tool More Flexible:                                 â”‚
     â”‚ def compare_time_periods(                                               â”‚
     â”‚     period_type: str = "custom",  # "month_over_month",                 â”‚
     â”‚ "quarter_over_quarter", "custom"                                        â”‚
     â”‚     reference_date: Optional[str] = None,  # Defaults to data end date  â”‚
     â”‚     current_start: Optional[str] = None,                                â”‚
     â”‚     current_end: Optional[str] = None,                                  â”‚
     â”‚     previous_start: Optional[str] = None,                               â”‚
     â”‚     previous_end: Optional[str] = None                                  â”‚
     â”‚ ) -> PeriodComparison:                                                  â”‚
     â”‚     """                                                                 â”‚
     â”‚     Compare two time periods.                                           â”‚
     â”‚                                                                         â”‚
     â”‚     If period_type="month_over_month" and reference_date is provided,   â”‚
     â”‚     automatically calculate:                                            â”‚
     â”‚       - Current period: The month containing reference_date             â”‚
     â”‚       - Previous period: The prior month                                â”‚
     â”‚                                                                         â”‚
     â”‚     If period_type="custom", use provided start/end dates.              â”‚
     â”‚     """                                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ 4. Document Date Assumptions:                                           â”‚
     â”‚ # README.md                                                             â”‚
     â”‚                                                                         â”‚
     â”‚ ## Data Generation & Time Periods                                       â”‚
     â”‚                                                                         â”‚
     â”‚ The generated data spans a fixed date range for reproducibility:        â”‚
     â”‚ - **Date Range**: 2024-01-01 to 2024-12-31                              â”‚
     â”‚ - **Seed**: 42 (deterministic)                                          â”‚
     â”‚                                                                         â”‚
     â”‚ When asking time-based questions:                                       â”‚
     â”‚ - "This month" refers to December 2024 (last month in data)             â”‚
     â”‚ - "Last month" refers to November 2024                                  â”‚
     â”‚ - Comparisons use complete calendar months only                         â”‚
     â”‚                                                                         â”‚
     â”‚ Plan Update Required:                                                   â”‚
     â”‚ 1. Modify generate_data.py to use fixed date or accept --end-date       â”‚
     â”‚ parameter                                                               â”‚
     â”‚ 2. Update DataManager to track data boundaries                          â”‚
     â”‚ 3. Enhance compare_time_periods with smart date calculation             â”‚
     â”‚ 4. Add tests with specific dates (not relative to "today")              â”‚
     â”‚ 5. Document date assumptions in README                                  â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 10.6 Testing & Evaluation Risk                                          â”‚
     â”‚                                                                         â”‚
     â”‚ ISSUE #6: Tests Require API Keys and Create Friction                    â”‚
     â”‚                                                                         â”‚
     â”‚ Problem:                                                                â”‚
     â”‚ - âŒ E2E tests call OpenAI API (requires evaluator's API key)           â”‚
     â”‚ - âŒ Tests cost money to run                                            â”‚
     â”‚ - âŒ Tests may be slow (~30s)                                           â”‚
     â”‚ - âŒ Tests may fail due to rate limits or API issues                    â”‚
     â”‚ - âŒ No way to validate correctness WITHOUT calling API                 â”‚
     â”‚                                                                         â”‚
     â”‚ Current Test Strategy:                                                  â”‚
     â”‚ # tests/test_agent.py                                                   â”‚
     â”‚ def test_agent_answers_revenue_question(agent):  # Calls OpenAI!        â”‚
     â”‚     response = agent("What is our total revenue by category?")          â”‚
     â”‚     assert "electronics" in response.lower()                            â”‚
     â”‚                                                                         â”‚
     â”‚ Risk Level: HIGH - Evaluators may not run tests, can't verify           â”‚
     â”‚ correctness easily                                                      â”‚
     â”‚                                                                         â”‚
     â”‚ Mitigation Strategy:                                                    â”‚
     â”‚                                                                         â”‚
     â”‚ 1. Separate Tool Tests from Agent Tests:                                â”‚
     â”‚ # tests/test_analytics.py - NO API CALLS                                â”‚
     â”‚ def test_revenue_by_category():                                         â”‚
     â”‚     """Test tool directly - fast, free, deterministic."""               â”‚
     â”‚     result = calculate_revenue_by_category()                            â”‚
     â”‚     assert result.total_revenue > 0                                     â”‚
     â”‚     # Validate with known data                                          â”‚
     â”‚                                                                         â”‚
     â”‚ # tests/test_agent_integration.py - REQUIRES API KEY                    â”‚
     â”‚ @pytest.mark.requires_api_key                                           â”‚
     â”‚ def test_agent_with_llm(agent):                                         â”‚
     â”‚     """Integration test - requires OPENAI_API_KEY."""                   â”‚
     â”‚     response = agent("What is our total revenue by category?")          â”‚
     â”‚     # Only run if API key present                                       â”‚
     â”‚                                                                         â”‚
     â”‚ 2. Add Mock/Cached Responses for Agent Tests:                           â”‚
     â”‚ # tests/test_agent_behavior.py - NO API CALLS                           â”‚
     â”‚ def test_agent_tool_selection():                                        â”‚
     â”‚     """Test agent behavior with mocked LLM responses."""                â”‚
     â”‚     with mock.patch('openai.ChatCompletion.create') as mock_llm:        â”‚
     â”‚         mock_llm.return_value = {                                       â”‚
     â”‚             "tool_calls": [{"function":                                 â”‚
     â”‚ "calculate_revenue_by_category"}]                                       â”‚
     â”‚         }                                                               â”‚
     â”‚         # Test that agent selects correct tool                          â”‚
     â”‚                                                                         â”‚
     â”‚ 3. Provide Pre-Generated Test Results:                                  â”‚
     â”‚ # tests/expected_outputs/                                               â”‚
     â”‚ revenue_by_category.json                                                â”‚
     â”‚ customer_ltv_top10.json                                                 â”‚
     â”‚ return_rates.json                                                       â”‚
     â”‚ ...                                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ # Tests can validate tools against these golden files                   â”‚
     â”‚                                                                         â”‚
     â”‚ 4. Update Test Running Instructions:                                    â”‚
     â”‚ # README.md                                                             â”‚
     â”‚                                                                         â”‚
     â”‚ ## Running Tests                                                        â”‚
     â”‚                                                                         â”‚
     â”‚ ### Tool Tests (No API Key Required) âœ“                                  â”‚
     â”‚ ```bash                                                                 â”‚
     â”‚ pytest tests/test_analytics.py -v                                       â”‚
     â”‚ pytest tests/test_data_loader.py -v                                     â”‚
     â”‚                                                                         â”‚
     â”‚ These tests are fast, free, and validate core business logic.           â”‚
     â”‚                                                                         â”‚
     â”‚ Agent Integration Tests (Requires API Key)                              â”‚
     â”‚                                                                         â”‚
     â”‚ export OPENAI_API_KEY=sk-...                                            â”‚
     â”‚ pytest tests/test_agent_integration.py -v                               â”‚
     â”‚                                                                         â”‚
     â”‚ Optional: Only run if you want to verify end-to-end behavior.           â”‚
     â”‚                                                                         â”‚
     â”‚ Validate Without Running Tests                                          â”‚
     â”‚                                                                         â”‚
     â”‚ # Check pre-generated outputs match expectations                        â”‚
     â”‚ python scripts/validate_outputs.py                                      â”‚
     â”‚                                                                         â”‚
     â”‚ **Plan Update Required**:                                               â”‚
     â”‚ 1. Split tests into tool tests (no API) and integration tests (API      â”‚
     â”‚ required)                                                               â”‚
     â”‚ 2. Use pytest marks: `@pytest.mark.requires_api_key`                    â”‚
     â”‚ 3. Add pre-generated expected outputs for validation                    â”‚
     â”‚ 4. Create `pytest.ini` to skip API tests by default                     â”‚
     â”‚ 5. Update README with clear test instructions                           â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ ### 10.7 Overall Design Trade-offs                                      â”‚
     â”‚                                                                         â”‚
     â”‚ **Assessment: Right-Sized or Over-Engineered?**                         â”‚
     â”‚                                                                         â”‚
     â”‚ **Over-Engineered Aspects** ğŸ”´                                          â”‚
     â”‚                                                                         â”‚
     â”‚ 1. **Three-Layer Architecture for 5 Tools**                             â”‚
     â”‚    - **Issue**: Separation of data_loader, analytics, agent might be    â”‚
     â”‚ overkill                                                                â”‚
     â”‚    - **Reality**: Could implement all in 2 files (tools + agent)        â”‚
     â”‚    - **Verdict**: KEEP - demonstrates architectural thinking for        â”‚
     â”‚ interview                                                               â”‚
     â”‚    - **Justification**: Shows production mindset, but acknowledge it's  â”‚
     â”‚ for demo purposes                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ 2. **Separate `data_loader.py` for ~20 Lines**                          â”‚
     â”‚    - **Issue**: DataManager class is probably just load_csv() twice     â”‚
     â”‚    - **Reality**: Could inline in analytics.py                          â”‚
     â”‚    - **Verdict**: KEEP but simplify - show architecture without bloat   â”‚
     â”‚                                                                         â”‚
     â”‚ 3. **`utils.py` Module**                                                â”‚
     â”‚    - **Issue**: Date parsing helpers might be 2-3 functions             â”‚
     â”‚    - **Reality**: Could inline or skip entirely                         â”‚
     â”‚    - **Verdict**: SKIP unless actually needed - don't create empty      â”‚
     â”‚ modules                                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ 4. **`test_data_generator.py`**                                         â”‚
     â”‚    - **Issue**: Does data generation need unit tests?                   â”‚
     â”‚    - **Reality**: Visual inspection + smoke test sufficient             â”‚
     â”‚    - **Verdict**: SKIP - focus testing on business logic                â”‚
     â”‚                                                                         â”‚
     â”‚ **Under-Specified Aspects** ğŸŸ¡                                          â”‚
     â”‚                                                                         â”‚
     â”‚ 1. **Agent Response Formatting**                                        â”‚
     â”‚    - **Issue**: No clear contract for agent output format               â”‚
     â”‚    - **Fix**: Added in Section 10.2 above                               â”‚
     â”‚                                                                         â”‚
     â”‚ 2. **Error Handling**                                                   â”‚
     â”‚    - **Issue**: No strategy for failures, missing data, unsupported     â”‚
     â”‚ queries                                                                 â”‚
     â”‚    - **Fix**: Added in Section 10.4 above                               â”‚
     â”‚                                                                         â”‚
     â”‚ 3. **Date/Time Handling**                                               â”‚
     â”‚    - **Issue**: Non-deterministic, unclear semantics                    â”‚
     â”‚    - **Fix**: Added in Section 10.5 above                               â”‚
     â”‚                                                                         â”‚
     â”‚ 4. **Tool Parameter Flexibility**                                       â”‚
     â”‚    - **Issue**: Tools too rigid for question variations                 â”‚
     â”‚    - **Fix**: Added in Section 10.3 above                               â”‚
     â”‚                                                                         â”‚
     â”‚ **Right-Sized Aspects** âœ…                                              â”‚
     â”‚                                                                         â”‚
     â”‚ 1. **5 Focused Tools**: Perfect granularity for LLM reliability         â”‚
     â”‚ 2. **Pydantic Models**: Essential for validation and structure          â”‚
     â”‚ 3. **Pandas Backend**: Appropriate for 5K-10K rows                      â”‚
     â”‚ 4. **Demo Script**: Exactly what evaluators need                        â”‚
     â”‚ 5. **README as Design Doc**: Dual-purpose documentation                 â”‚
     â”‚                                                                         â”‚
     â”‚ **Recommendation**:                                                     â”‚
     â”‚ - **Keep**: Architecture layers (demonstrates thinking)                 â”‚
     â”‚ - **Simplify**: data_loader to minimal viable implementation            â”‚
     â”‚ - **Skip**: utils.py unless needed, test_data_generator.py              â”‚
     â”‚ - **Add**: Error handling, response structure, flexible parameters      â”‚
     â”‚ - **Fix**: Date determinism, test strategy                              â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ ### 10.8 Summary Assessment                                             â”‚
     â”‚                                                                         â”‚
     â”‚ **Key Strengths** âœ…                                                    â”‚
     â”‚                                                                         â”‚
     â”‚ 1. **Clean Architecture**: Three-layer design shows production thinking â”‚
     â”‚ 2. **Structured Tools**: Smart choice for LLM reliability               â”‚
     â”‚ 3. **Testability**: Separation enables good testing (once fixed)        â”‚
     â”‚ 4. **Right-Sized for Assignment**: Not over-engineered (mostly)         â”‚
     â”‚ 5. **Clear Rationale**: Every decision has documented reasoning         â”‚
     â”‚                                                                         â”‚
     â”‚ **Primary Risks** âš ï¸                                                    â”‚
     â”‚                                                                         â”‚
     â”‚ | Risk | Severity | Status | Mitigation |                               â”‚
     â”‚ |------|----------|--------|------------|                               â”‚
     â”‚ | Agent returns free-text, not structured | HIGH | âŒ Not addressed |   â”‚
     â”‚ Add AgentResponse schema (10.2) |                                       â”‚
     â”‚ | Data generation mismatch | HIGH | âŒ Conflicts with existing | Use    â”‚
     â”‚ root generate_data.py (10.1) |                                          â”‚
     â”‚ | Non-deterministic dates | HIGH | âŒ Will cause test failures | Fix    â”‚
     â”‚ dates to 2024 range (10.5) |                                            â”‚
     â”‚ | Tests require API keys | HIGH | âŒ Evaluator friction | Split         â”‚
     â”‚ tool/integration tests (10.6) |                                         â”‚
     â”‚ | Inflexible tools | MEDIUM | âš ï¸ Partial | Add optional parameters      â”‚
     â”‚ (10.3) |                                                                â”‚
     â”‚ | No error handling | MEDIUM | âŒ Not addressed | Add error responses   â”‚
     â”‚ (10.4) |                                                                â”‚
     â”‚ | Some over-engineering | LOW | âš ï¸ Minor | Simplify where noted (10.7) |â”‚
     â”‚                                                                         â”‚
     â”‚ **Blind Spots** ğŸ”                                                      â”‚
     â”‚                                                                         â”‚
     â”‚ 1. **Output Contract**: Biggest gap - tools are structured but agent    â”‚
     â”‚ response isn't                                                          â”‚
     â”‚ 2. **Date Semantics**: Unclear how "this month" gets calculated         â”‚
     â”‚ 3. **Error Cases**: No plan for unsupported questions or missing data   â”‚
     â”‚ 4. **Evaluator Experience**: Tests create friction instead of confidenceâ”‚
     â”‚ 5. **Data Alignment**: Plan assumes different data than what exists     â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚                                                                         â”‚
     â”‚ ## 11. Concrete Recommendations (Priority Order)                        â”‚
     â”‚                                                                         â”‚
     â”‚ ### ğŸ”´ CRITICAL (Must Fix Before Implementation)                        â”‚
     â”‚                                                                         â”‚
     â”‚ **1. Align Data Generation with Assignment**                            â”‚
     â”‚ ```bash                                                                 â”‚
     â”‚ Action: Use existing generate_data.py at root level                     â”‚
     â”‚ Changes Required:                                                       â”‚
     â”‚ - Remove src/data_generator.py from plan                                â”‚
     â”‚ - Add --seed parameter to existing script for determinism               â”‚
     â”‚ - Fix date range to static 2024-01-01 to 2024-12-31                     â”‚
     â”‚ - Update all references from 10K/500 to actual 5K/200                   â”‚
     â”‚                                                                         â”‚
     â”‚ 2. Add Structured Agent Response Schema                                 â”‚
     â”‚ Action: Create unified AgentResponse model                              â”‚
     â”‚ Changes Required:                                                       â”‚
     â”‚ - Add AgentResponse to models.py                                        â”‚
     â”‚ - Configure agent with output_schema=AgentResponse                      â”‚
     â”‚ - Update demo to show structured outputs                                â”‚
     â”‚ - Add tests validating response structure                               â”‚
     â”‚                                                                         â”‚
     â”‚ 3. Fix Time-Based Query Determinism                                     â”‚
     â”‚ Action: Make date handling reproducible                                 â”‚
     â”‚ Changes Required:                                                       â”‚
     â”‚ - Update generate_data.py to use fixed end_date                         â”‚
     â”‚ - Add date range context to DataManager                                 â”‚
     â”‚ - Make compare_time_periods accept period labels                        â”‚
     â”‚ - Document date assumptions in README                                   â”‚
     â”‚                                                                         â”‚
     â”‚ 4. Split Tests: Tool vs. Agent                                          â”‚
     â”‚ Action: Separate free tests from API-required tests                     â”‚
     â”‚ Changes Required:                                                       â”‚
     â”‚ - Move tool tests to test_analytics.py (no API)                         â”‚
     â”‚ - Move agent tests to test_agent_integration.py (@requires_api)         â”‚
     â”‚ - Update pytest.ini to skip API tests by default                        â”‚
     â”‚ - Update README with clear test instructions                            â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸŸ¡ IMPORTANT (Strongly Recommended)                                     â”‚
     â”‚                                                                         â”‚
     â”‚ 5. Add Error Handling Strategy                                          â”‚
     â”‚ Action: Handle unsupported queries gracefully                           â”‚
     â”‚ Changes Required:                                                       â”‚
     â”‚ - Add ErrorResponse model                                               â”‚
     â”‚ - Add explain_capabilities tool                                         â”‚
     â”‚ - Update system message with boundaries                                 â”‚
     â”‚ - Test unsupported question handling                                    â”‚
     â”‚                                                                         â”‚
     â”‚ 6. Make Tools More Flexible                                             â”‚
     â”‚ Action: Add optional filter parameters                                  â”‚
     â”‚ Changes Required:                                                       â”‚
     â”‚ - Add category/region/segment filters to tools                          â”‚
     â”‚ - Update tool docstrings with examples                                  â”‚
     â”‚ - Test question variations                                              â”‚
     â”‚                                                                         â”‚
     â”‚ ğŸŸ¢ NICE-TO-HAVE (Time Permitting)                                       â”‚
     â”‚                                                                         â”‚
     â”‚ 7. Simplify Over-Engineered Parts                                       â”‚
     â”‚ - Skip utils.py unless actually needed                                  â”‚
     â”‚ - Skip test_data_generator.py                                           â”‚
     â”‚ - Keep data_loader.py but implement minimally                           â”‚
     â”‚                                                                         â”‚
     â”‚ 8. Add Pre-Generated Test Outputs                                       â”‚
     â”‚ - Create expected_outputs/ directory                                    â”‚
     â”‚ - Add golden file validation script                                     â”‚
     â”‚ - Enables validation without API calls                                  â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 12. Updated Implementation Checklist                                    â”‚
     â”‚                                                                         â”‚
     â”‚ Phase 1: Foundation (30 min)                                            â”‚
     â”‚                                                                         â”‚
     â”‚ - Create directory structure                                            â”‚
     â”‚ - Set up config.py                                                      â”‚
     â”‚ - Create models.py with ALL schemas (including AgentResponse,           â”‚
     â”‚ ErrorResponse)                                                          â”‚
     â”‚ - Create .env.example                                                   â”‚
     â”‚ - NEW: Fix generate_data.py to use fixed dates and seed                 â”‚
     â”‚                                                                         â”‚
     â”‚ Phase 2: Data Layer (20 min - SIMPLIFIED)                               â”‚
     â”‚                                                                         â”‚
     â”‚ - Run generate_data.py to create CSVs                                   â”‚
     â”‚ - Implement minimal data_loader.py (DataManager class)                  â”‚
     â”‚ - Add data boundary tracking to DataManager                             â”‚
     â”‚ - Test data loads correctly                                             â”‚
     â”‚                                                                         â”‚
     â”‚ Phase 3: Business Logic (45 min)                                        â”‚
     â”‚                                                                         â”‚
     â”‚ - Implement 5 tools in analytics.py                                     â”‚
     â”‚ - NEW: Add optional filter parameters to tools                          â”‚
     â”‚ - NEW: Add explain_capabilities tool                                    â”‚
     â”‚ - Test each tool manually                                               â”‚
     â”‚                                                                         â”‚
     â”‚ Phase 4: Agent Setup (20 min)                                           â”‚
     â”‚                                                                         â”‚
     â”‚ - Implement agent.py with OpenAI config                                 â”‚
     â”‚ - NEW: Configure with output_schema=AgentResponse                       â”‚
     â”‚ - NEW: Add comprehensive system message with boundaries                 â”‚
     â”‚ - Test one question end-to-end                                          â”‚
     â”‚                                                                         â”‚
     â”‚ Phase 5: Testing & Demo (30 min)                                        â”‚
     â”‚                                                                         â”‚
     â”‚ - Write tool unit tests (NO API CALLS)                                  â”‚
     â”‚ - NEW: Write agent integration tests (@requires_api_key)                â”‚
     â”‚ - NEW: Add pytest.ini to skip API tests by default                      â”‚
     â”‚ - Create demo.py showing structured outputs                             â”‚
     â”‚ - Run all tests                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ Phase 6: Documentation (20 min)                                         â”‚
     â”‚                                                                         â”‚
     â”‚ - Write README with setup instructions                                  â”‚
     â”‚ - NEW: Document output format and structure                             â”‚
     â”‚ - NEW: Explain date range and assumptions                               â”‚
     â”‚ - NEW: Clear test running instructions                                  â”‚
     â”‚ - Add docstrings everywhere                                             â”‚
     â”‚                                                                         â”‚
     â”‚ Total Estimated Time: 3 hours (extended from 2:45 due to critical fixes)â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 13. Strands SDK Documentation Review                                    â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Official Documentation Reviewed                                      â”‚
     â”‚                                                                         â”‚
     â”‚ Sources:                                                                â”‚
     â”‚ - https://strandsagents.com/latest/documentation/docs/user-guide/quickstâ”‚
     â”‚ art/python/                                                             â”‚
     â”‚ - https://strandsagents.com/latest/documentation/docs/user-guide/conceptâ”‚
     â”‚ s/model-providers/openai/                                               â”‚
     â”‚ - https://strandsagents.com/latest/documentation/docs/user-guide/conceptâ”‚
     â”‚ s/tools/custom-tools/                                                   â”‚
     â”‚ - https://github.com/strands-agents/sdk-python                          â”‚
     â”‚                                                                         â”‚
     â”‚ Key Findings for Implementation                                         â”‚
     â”‚                                                                         â”‚
     â”‚ 1. Tool Decorator Pattern (Confirmed)                                   â”‚
     â”‚                                                                         â”‚
     â”‚ from strands import tool                                                â”‚
     â”‚                                                                         â”‚
     â”‚ @tool                                                                   â”‚
     â”‚ def my_function(param: str) -> dict:                                    â”‚
     â”‚     """Docstring is used by LLM to understand tool purpose."""          â”‚
     â”‚     return {"result": "value"}                                          â”‚
     â”‚                                                                         â”‚
     â”‚ - Docstrings are critical - LLM reads them to understand tool purpose   â”‚
     â”‚ - Type hints automatically generate tool specifications                 â”‚
     â”‚ - Return types can be dict, Pydantic models, or JSON-serializable       â”‚
     â”‚ objects                                                                 â”‚
     â”‚                                                                         â”‚
     â”‚ 2. OpenAI Model Configuration (Confirmed)                               â”‚
     â”‚                                                                         â”‚
     â”‚ from strands.models.openai import OpenAIModel                           â”‚
     â”‚                                                                         â”‚
     â”‚ model = OpenAIModel(                                                    â”‚
     â”‚     client_args={"api_key": os.getenv("OPENAI_API_KEY")},               â”‚
     â”‚     model_id="gpt-4o",  # or "gpt-4o-mini"                              â”‚
     â”‚     params={                                                            â”‚
     â”‚         "temperature": 0.0,    # Deterministic for analytics            â”‚
     â”‚         "max_tokens": 2000,                                             â”‚
     â”‚     }                                                                   â”‚
     â”‚ )                                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ - Install: pip install 'strands-agents[openai]' (already installed in   â”‚
     â”‚ .venv)                                                                  â”‚
     â”‚ - API key via environment variable or client_args                       â”‚
     â”‚ - Supported models: gpt-4o, gpt-4o-mini, gpt-4-turbo                    â”‚
     â”‚                                                                         â”‚
     â”‚ 3. Agent Setup Pattern (Confirmed)                                      â”‚
     â”‚                                                                         â”‚
     â”‚ from strands import Agent                                               â”‚
     â”‚                                                                         â”‚
     â”‚ agent = Agent(                                                          â”‚
     â”‚     model=model,                                                        â”‚
     â”‚     tools=[tool1, tool2, tool3]                                         â”‚
     â”‚ )                                                                       â”‚
     â”‚                                                                         â”‚
     â”‚ response = agent("Your question here")                                  â”‚
     â”‚                                                                         â”‚
     â”‚ - Simple instantiation with model and tools list                        â”‚
     â”‚ - Tools automatically registered and made available to LLM              â”‚
     â”‚                                                                         â”‚
     â”‚ 4. Structured Output Support (Confirmed)                                â”‚
     â”‚                                                                         â”‚
     â”‚ - Tools can return Pydantic models directly                             â”‚
     â”‚ - Return format: {"status": "success", "content": [{"json": data}]}     â”‚
     â”‚ - ToolResult structure accepts JSON-serializable data                   â”‚
     â”‚                                                                         â”‚
     â”‚ 5. Best Practices Extracted                                             â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Docstrings: Write detailed descriptions - LLM uses them for tool     â”‚
     â”‚ selection                                                               â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Type Hints: Use Optional[str] for optional parameters, List[str] for â”‚
     â”‚ lists                                                                   â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Return Types: Pydantic models work seamlessly with @tool decorator   â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Error Handling: Return dict with "status" and "content" keys for     â”‚
     â”‚ errors                                                                  â”‚
     â”‚                                                                         â”‚
     â”‚ âš ï¸ Note: Agent-level structured output schema (AgentResponse wrapper)   â”‚
     â”‚ not documented - may need custom implementation or post-processing      â”‚
     â”‚                                                                         â”‚
     â”‚ Alignment Check                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”                                                                  â”‚
     â”‚ â”‚          Planned Feature          â”‚   SDK Support   â”‚        Status   â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ @tool decorator with Pydantic     â”‚ âœ… Documented   â”‚ Aligned         â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”‚ returns                           â”‚                 â”‚                 â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ OpenAI GPT-4 configuration        â”‚ âœ… Documented   â”‚ Aligned         â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ temperature=0.0 for deterministic â”‚ âœ… Supported    â”‚ Aligned         â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Tool docstrings for LLM           â”‚ âœ… Required     â”‚ Aligned         â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”¤                                                                  â”‚
     â”‚ â”‚ Agent-level output schema         â”‚ âš ï¸ Not          â”‚ May need custom â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â”‚                                   â”‚ documented      â”‚ wrapper         â”‚
     â”‚      â”‚                                                                  â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ â”€â”€â”€â”€â”€â”˜                                                                  â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ 14. Final Validation: Plan-Data Alignment Confirmed                     â”‚
     â”‚                                                                         â”‚
     â”‚ âœ… Complete Understanding Verified                                      â”‚
     â”‚                                                                         â”‚
     â”‚ generate_data.py Analysis Summary:                                      â”‚
     â”‚ 1. âœ… File structure understood: Reviewed all 94 lines, understand      â”‚
     â”‚ implementation                                                          â”‚
     â”‚ 2. âœ… Data schema validated: All fields match assignment requirements   â”‚
     â”‚ perfectly                                                               â”‚
     â”‚ 3. âœ… Tool compatibility confirmed: All 5 tools can be implemented with â”‚
     â”‚ this schema                                                             â”‚
     â”‚ 4. âœ… Critical issues identified: datetime.now() and output directory   â”‚
     â”‚ need fixing                                                             â”‚
     â”‚ 5. âœ… Expected ranges calculated: Know what realistic values look like  â”‚
     â”‚ for validation                                                          â”‚
     â”‚ 6. âœ… Plan updated: All sections now reflect actual implementation      â”‚
     â”‚                                                                         â”‚
     â”‚ Key Findings from Analysis:                                             â”‚
     â”‚ - Script generates exactly what assignment requires (schema match 100%) â”‚
     â”‚ - Only 2 critical fixes needed: datetime.now() â†’ fixed date, output pathâ”‚
     â”‚  â†’ data/ subdirectory                                                   â”‚
     â”‚ - Seed=42 provides reproducibility for testing âœ“                        â”‚
     â”‚ - Base prices and distributions are reasonable for demo âœ“               â”‚
     â”‚ - All tool implementations will have required fields available âœ“        â”‚
     â”‚                                                                         â”‚
     â”‚ Confidence Level: ğŸŸ¢ HIGH                                               â”‚
     â”‚ - Data generation fully understood                                      â”‚
     â”‚ - Plan accurately reflects implementation                               â”‚
     â”‚ - All tools mappable to available fields                                â”‚
     â”‚ - No schema mismatches or missing data concerns                         â”‚
     â”‚                                                                         â”‚
     â”‚ Ready for Implementation: âœ… YES                                        â”‚
     â”‚ - Clear modification instructions (specific line numbers)               â”‚
     â”‚ - Validation checks defined for each step                               â”‚
     â”‚ - Expected data ranges documented for testing                           â”‚
     â”‚ - No blocking issues or uncertainties                                   â”‚
     â”‚                                                                         â”‚
     â”‚ ---                                                                     â”‚
     â”‚ This plan positions you to deliver a portfolio-quality implementation   â”‚
     â”‚ that showcases Lead AI Engineer level thinking: not just making         â”‚
     â”‚ something work, but architecting a maintainable, testable,              â”‚
     â”‚ production-grade system that happens to use AI.       